{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam10816/CS22M082_ASSIGNEMNT_1/blob/q2/March_10__neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hhgoo0AzGUZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0597083-ba4e-4a83-901d-0a0ca1b221b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function _WandbInit._resume_backend at 0x7f6bd9b5d040> (for pre_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.11)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "Error in callback <function _WandbInit._pause_backend at 0x7f6bd9b5d4c0> (for post_run_cell):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BrokenPipeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pausing backend\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/interface/interface_sock.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_record_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     def _communicate_async(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mserver_req\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mServerRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mserver_req\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_publish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_req\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_extract_packet_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36msend_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<BI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sendall_with_error_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_server_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/lib/sock_client.py\u001b[0m in \u001b[0;36m_sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# sent equal to 0 indicates a closed socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project = \"Assignment 1_new\" ,name = \"Question 1\")\n",
        "\n",
        "\n",
        "titles = [\"T-Shirt/Top\",\"Trouser\",\"Pullover\",\"Dress\",\"Sself.hirts\",\"Sandal\",\"Coat\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "fig,axs = plt.subplots(2,5,figsize=(20,6))\n",
        "axs =axs.flatten()\n",
        "images=[]\n",
        "for i in range(0,10):\n",
        "  index =random.choice(np.where(train_labels==i)[0])\n",
        "  \n",
        "  axs[i].imshow(train_data[index],cmap=\"gray\")\n",
        "  axs[i].set_title(titles[i])\n",
        "  Img = wandb.Image(train_data[index],caption=[titles[i]])\n",
        "  images.append(Img)\n",
        "wandb.log({\"examples\":images})\n",
        "  "
      ],
      "metadata": {
        "id": "CG7IszZv9655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "dcb1951f-e1fc-4f5b-d7a2-cf054f7f4cf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivam-kharat-94\u001b[0m (\u001b[33mvilgax\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230310_190425-6edhr05p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vilgax/Assignment%201/runs/6edhr05p' target=\"_blank\">Question 1</a></strong> to <a href='https://wandb.ai/vilgax/Assignment%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vilgax/Assignment%201' target=\"_blank\">https://wandb.ai/vilgax/Assignment%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vilgax/Assignment%201/runs/6edhr05p' target=\"_blank\">https://wandb.ai/vilgax/Assignment%201/runs/6edhr05p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x432 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p4rX01kwJw7"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = np.reshape(train_data,(len(train_data),train_data.shape[1]**2))\n",
        "test_data = np.reshape(test_data,(len(test_data),test_data.shape[1]**2))\n",
        "test_labels =np.reshape(test_labels,(1,len(test_data)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qviYKZc-UJTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2/3**"
      ],
      "metadata": {
        "id": "dmMY0qTlUMea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qOS7o3xrG1Yn"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "import torch\n",
        "from numpy.core.multiarray import MAY_SHARE_EXACT\n",
        "from re import M\n",
        "from matplotlib.lines import STEP_LOOKUP_MAP\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "train_data = np.reshape(train_data/255.0,(len(train_data),train_data.shape[1]**2))\n",
        "test_data = np.reshape(test_data/255.0,(len(test_data),test_data.shape[1]**2))\n",
        "test_labels =np.reshape(test_labels,(1,len(test_data)))\n",
        "\n",
        "\n",
        "class neural_network:\n",
        "\n",
        "  #it initializes W and b\n",
        "  def __init__(self):\n",
        "    \n",
        "    (train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "    train_data = np.reshape(train_data/255.0,(len(train_data),train_data.shape[1]**2))\n",
        "    self.test_data = np.reshape(test_data/255.0,(len(test_data),test_data.shape[1]**2))\n",
        "    self.test_labels =test_labels #np.reshape(test_labels,(1,len(test_data)))\n",
        "\n",
        "    l=int(train_data.shape[0]/100)*80\n",
        "    self.train_data=train_data[0:l]\n",
        "    self.train_label=train_labels[0:l]\n",
        "    self.validation_data = train_data[l:]\n",
        "    self.validation_label = train_labels[l:]\n",
        "    \n",
        "  #def train(self,epoch=10,hidden_layers=3,size_of_layer=32,weight_decay=0,learning_rate=0.01,optimizer=\"sgd\",batch_size=32,weight_init=\"random\",activation=\"sigmoid\"):\n",
        "\n",
        "  def train(self,weight_init=\"random\",hidden_layers=3,size_of_layer=32,activation=\"sigmoid\",optimizer=\"sgd\",learning_rate=0.01,epoch=10,batch_size=32,weight_decay=0,loss=\"cross_entropy\"):\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    self.loss = loss\n",
        "    self.hi=[size_of_layer]*hidden_layers\n",
        "    self.activation =activation\n",
        "    if(weight_init==\"Xavier\"):\n",
        "      self.xav()\n",
        "    elif(weight_init==\"random\"):\n",
        "      self.rndm()\n",
        "   \n",
        "    if(optimizer==\"sgd\"):\n",
        "      self.sgd(step_size=learning_rate,batch_size =batch_size,epoch=epoch,reg=weight_decay)\n",
        "    elif(optimizer==\"momentum\"):\n",
        "      self.mbgd(step_size=learning_rate,batch_size =batch_size,epoch=epoch,beta=0.75,reg=weight_decay)\n",
        "    elif(optimizer==\"nesterov\"):\n",
        "      self.nagd(step_size=learning_rate,batch_size =batch_size,epoch=epoch,reg=weight_decay)\n",
        "    elif(optimizer==\"rmsprop\"):\n",
        "      self.rmsprop(step_size=learning_rate,batch_size =batch_size,epoch=epoch,reg=weight_decay)\n",
        "    elif(optimizer==\"adam\"):\n",
        "      self.adam(step_size=learning_rate,batch_size =batch_size,epoch=epoch,reg=weight_decay)\n",
        "    elif(optimizer==\"nadam\"):\n",
        "      self.nadam(step_size=learning_rate,batch_size =batch_size,epoch=epoch,reg=weight_decay)\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def xav(self):\n",
        "    l= self.train_data.shape[1]\n",
        "\n",
        "    self.W =[self.xavier_init(self.hi[0],l)] \n",
        "    self.b =[self.xavier_init(1,self.hi[0])]\n",
        "    for i in range(1,len(self.hi)) :\n",
        "      self.W.append(self.xavier_init(self.hi[i],self.hi[i-1]))\n",
        "      self.b.append(self.xavier_init(1,self.hi[i])) \n",
        "    self.W.append(self.xavier_init(10,self.hi[-1]))\n",
        "    \n",
        "    self.b.append(self.xavier_init(1,10))\n",
        "  \n",
        "\n",
        "  def rndm(self):\n",
        "    l= train_data.shape[1]\n",
        "\n",
        "    self.W =[np.random.randn(self.hi[0],l)] \n",
        "    self.b =[np.random.randn(1,self.hi[0])]\n",
        "    for i in range(1,len(self.hi)) :\n",
        "      self.W.append(np.random.randn(self.hi[i],self.hi[i-1]))\n",
        "      self.b.append(np.random.randn(1,self.hi[i])) \n",
        "    self.W.append(np.random.randn(10,self.hi[-1]))\n",
        "    \n",
        "    self.b.append(np.random.randn(1,10))\n",
        "\n",
        "  def relu(self,matrix):\n",
        "\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    matrix -- a NumPy array or matrix\n",
        "    Returns:\n",
        "    A NumPy array or matrix of the same shape as the input matrix,\n",
        "    with ReLU applied to each element.\n",
        "    \"\"\"\n",
        "    return np.maximum(matrix, 0) \n",
        "\n",
        "  def relu_derivative(self,matrix):\n",
        "    \n",
        "    # Create a copy of the input matrix and convert to float\n",
        "    derivative = np.array(matrix, dtype=np.float64)\n",
        "    \n",
        "    # Set negative values to 0\n",
        "    derivative[derivative < 0] = 0\n",
        "    \n",
        "    # Set positive values to 1\n",
        "    derivative[derivative > 0] = 1\n",
        "\n",
        "    return derivative\n",
        "\n",
        "  def tanh(self,matrix):\n",
        "    \n",
        "    # Avoid overflow by scaling inputs to the range [-100, 100]\n",
        "    x = np.clip(matrix, -100, 100)\n",
        "    \n",
        "    # Apply tanh element-wise\n",
        "    return np.tanh(x)\n",
        "\n",
        "  def tanh_derivative(self,matrix):\n",
        "   \n",
        "    # Avoid overflow by scaling inputs to the range [-100, 100]\n",
        "    x = np.clip(matrix, -100, 100)\n",
        "    \n",
        "    # Compute tanh element-wise\n",
        "    tanh_x = np.tanh(x)\n",
        "    \n",
        "    # Compute derivative of tanh element-wise\n",
        "    derivative = 1 - tanh_x**2\n",
        "    \n",
        "    \n",
        "    \n",
        "    return derivative\n",
        "\n",
        " \n",
        "  def WX_plus_B(self,W, X, b):\n",
        "    \n",
        "    result = np.dot(X, W.transpose())\n",
        "    row_count = result.shape[0]\n",
        "    \n",
        "    row_matrix_repeated = np.tile(b, (row_count, 1))\n",
        "    return result + row_matrix_repeated\n",
        "\n",
        "\n",
        "  def xavier_init(self,n, m):\n",
        "    # Calculate the Xavier initialization scale factor\n",
        "    xavier_scale = np.sqrt(2.0 / (n + m))\n",
        "\n",
        "    # Use numpy's random function to generate a matrix of shape (n, m)\n",
        "    matrix = np.random.randn(n, m) * xavier_scale\n",
        "\n",
        "    return matrix\n",
        "\n",
        "  #calculates sigmoid for matrix\n",
        "  def sigmoid(self,x):\n",
        "  \n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "  \n",
        "  def sum_columns(self,matrix):\n",
        "    if isinstance(matrix, np.ndarray):\n",
        "        # if matrix is a numpy array, convert it to a list\n",
        "        matrix = matrix.tolist()\n",
        "    \n",
        "    # sum the elements of each column and store in a list\n",
        "    column_sums = [sum(col) for col in zip(*matrix)]\n",
        "    \n",
        "    # convert the list to a 2D matrix of shape (1 x n)\n",
        "    row_matrix = np.array([column_sums])\n",
        "    \n",
        "    return row_matrix\n",
        "  #softmax for matrix\n",
        "  def softmax(self,x):\n",
        "    # Subtract the maximum value in each row from all the values in that row\n",
        "    # to prevent numerical instability from very large or very small values\n",
        "    # in the exponentials of the softmax function.\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
        "  \n",
        "  def subtract_matrices(self,W, W_theta, step_size):\n",
        "    \"\"\"\n",
        "    Subtract the matrices in the second list from the matrices in the first list, after multiplying the matrices in the\n",
        "    second list by a step size.\n",
        "\n",
        "    Args:\n",
        "        first_list (list): A list of numpy arrays representing the first set of matrices.\n",
        "        second_list (list): A list of numpy arrays representing the second set of matrices.\n",
        "        step_size (float): The step size to multiply the second set of matrices by.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of numpy arrays representing the result of subtracting the second set of matrices from the first set\n",
        "        of matrices after multiplying the second set of matrices by the step size.\n",
        "    \"\"\"\n",
        "    result_list = []\n",
        "    for i in range(len(self.W)):\n",
        "        result = W[i] - step_size * (W_theta[i])\n",
        "        result_list.append(result)\n",
        "    return result_list\n",
        "\n",
        "  def sigmoid_derivative(self,matrix):\n",
        "    \"\"\"\n",
        "    Calculate the derivative of the sigmoid function on a 2D matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (numpy.ndarray): A numpy array representing the matrix.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A numpy array representing the result of calculating the sigmoid derivative on the matrix.\n",
        "    \"\"\"\n",
        "    shift = np.max(matrix, axis=1, keepdims=True)\n",
        "    exp_matrix = np.exp(matrix - shift)\n",
        "    sig = 1 / (1 + exp_matrix)\n",
        "    return sig * (1 - sig)\n",
        "  \n",
        "  \n",
        "\n",
        "  def mean_squared_error(self,y_hat, y):\n",
        "    n = y_hat.shape[0]  # number of samples\n",
        "    k = y.astype(int)  # convert y to integer type for indexing\n",
        "    y_k = np.zeros((n, 10))  # create a one-hot encoding of y\n",
        "    y_k[np.arange(n), k] = 1\n",
        "    \n",
        "    # Calculate mean squared error\n",
        "    mse = np.mean((y_hat - y_k)**2)\n",
        "    \n",
        "    return mse\n",
        "  \n",
        "  def mean_squared_error_derivative(self,y_hat, y):\n",
        "    n = y_hat.shape[0]  # number of samples\n",
        "    k = y.astype(int)  # convert y to integer type for indexing\n",
        "    y_k = np.zeros((n, 10))  # create a one-hot encoding of y\n",
        "    y_k[np.arange(n), k] = 1\n",
        "    \n",
        "    # Calculate derivative\n",
        "    dMSE_dy_hat = (2/n) * (y_hat - y_k)\n",
        "    \n",
        "    return dMSE_dy_hat\n",
        "  def cross_entropy_loss_derivative(self,y_hat, Y):\n",
        "    ey = np.zeros((y_hat.shape[0],y_hat.shape[1]))\n",
        "\n",
        "    for i in range(0,len(Y)):\n",
        "      ey[i][Y[i]]=1\n",
        "    \n",
        "    return (-(ey-y_hat))\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    A,H,y_hat =self.forward_pro(X_test,self.W,self.b)\n",
        "  \n",
        "    y_pred = np.argmax(y_hat, axis=1)\n",
        "    return y_pred\n",
        "  def forward_pro(self,X,W,b):\n",
        "    A=[]\n",
        "    H=[]\n",
        "    A.append(self.WX_plus_B(W[0],X,b[0])) # a0 = WoX +bo\n",
        "\n",
        "    for i in range(1,len(self.hi)):\n",
        "\n",
        "      H.append(self.activation_fun(A[-1])) # hi = g(ai)\n",
        "      #print(H[i-1])\n",
        "      A.append( self.WX_plus_B(W[i],H[-1],b[i])) # ai = WiX +bi\n",
        "\n",
        "    H.append(self.activation_fun(A[-1]))\n",
        "    A.append(self.WX_plus_B(W[-1],H[-1],b[-1]))\n",
        "    \n",
        "    y_hat = self.softmax((A[-1]))\n",
        "    \n",
        "    \n",
        "    \n",
        "    return A,H,y_hat\n",
        "\n",
        "  def back_prop(self,X,Y,A,H,y_hat):\n",
        "    W_theta , b_theta,H_theta,A_theta =[],[],[],[]\n",
        "    \n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "    L =len(A)\n",
        "    if(self.loss==\"cross_entropy\"):\n",
        "      A_theta.append(self.cross_entropy_loss_derivative(y_hat,Y))\n",
        "    if(self.loss==\"MSE\"):\n",
        "      A_theta.append(self.mean_squared_error_derivative(y_hat,Y))\n",
        "    \n",
        "    #-------------------------\n",
        "    for k in range(L-1,0,-1):\n",
        "      \n",
        "      W_theta.append((np.matmul(A_theta[-1].transpose(),H[k-1])+self.reg*self.W[k]) ) # athetak*h[k-1]\n",
        "      b_theta.append( self.sum_columns(A_theta[-1]))\n",
        "      H_theta.append(np.matmul(A_theta[-1],self.W[k]))\n",
        "  \n",
        "      A_theta.append(H_theta[-1]*self.activation_derivative(A[k-1]))\n",
        "\n",
        "    W_theta.append((np.matmul(A_theta[-1].transpose(),X)+self.reg*self.W[0]))\n",
        "    b_theta.append(self.sum_columns(A_theta[-1]))\n",
        "\n",
        "    W_theta.reverse()\n",
        "    b_theta.reverse()\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    return W_theta , b_theta\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  def accuracy(self, X_test, y_test):\n",
        "    \n",
        "    # Feed forward through the network\n",
        "    A,H,y_hat =self.forward_pro(X_test,self.W,self.b)\n",
        "    \n",
        "    \n",
        "    y_pred = np.argmax(y_hat, axis=1)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    acc = np.mean(y_pred == y_test)\n",
        "    # Calculate accuracy\n",
        "    \n",
        "\n",
        "    return acc\n",
        "\n",
        "  def cross_entropy(self,y_hat,Y):\n",
        "      sum=0.0;\n",
        "      for i in range(0,len(Y)):\n",
        "        sum+=(-np.log2(y_hat[i][Y[i]]))\n",
        "      sum/= float(len(Y))\n",
        "      return sum\n",
        "  \n",
        "  def sgd(self,step_size,batch_size,epoch,reg=0.9):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "    rate = step_size\n",
        "    for e in range(0,epoch):\n",
        "      step_size=rate/(e+1)\n",
        "      start_time = time.time()\n",
        "      for k in range(0,N):\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,self.W,self.b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "          self.b =self.subtract_matrices(self.b,db,step_size)\n",
        "          self.W =self.subtract_matrices(self.W,dW,step_size)\n",
        "          \n",
        "          \n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "      \n",
        "  def mbgd(self,step_size,batch_size,epoch,beta=0.9,reg=0):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "\n",
        "    prev_ub , prev_uw =[],[]\n",
        "\n",
        "    for i in range(len(self.W)):\n",
        "      prev_ub.append(np.zeros((self.b[i].shape[0],self.b[i].shape[1])))\n",
        "      prev_uw.append(np.zeros((self.W[i].shape[0],self.W[i].shape[1])))\n",
        "\n",
        "\n",
        "    rate = step_size\n",
        "    for e in range(0,epoch):\n",
        "      step_size=rate/(e+1)\n",
        "      start_time = time.time()\n",
        "      beta_t=beta\n",
        "      for k in range(0,N):\n",
        "          ub,uw = list(prev_ub),list(prev_uw)\n",
        "\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,self.W,self.b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "\n",
        "          for i in range(len(self.W)):\n",
        "            ub[i]= beta_t*prev_ub[i] + db[i]\n",
        "            uw[i]= beta_t*prev_uw[i] + dW[i]\n",
        "          self.b =self.subtract_matrices(self.b,ub,step_size)\n",
        "          self.W =self.subtract_matrices(self.W,uw,step_size)\n",
        "\n",
        "          prev_ub , prev_uw = list(ub),list(uw)\n",
        "\n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "      \n",
        "  def nagd(self,step_size,batch_size,epoch,beta=0.9,reg=0):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "\n",
        "    prev_ub , prev_uw =[],[]\n",
        "\n",
        "    for i in range(len(self.W)):\n",
        "      prev_ub.append(np.zeros((self.b[i].shape[0],self.b[i].shape[1])))\n",
        "      prev_uw.append(np.zeros((self.W[i].shape[0],self.W[i].shape[1])))\n",
        "\n",
        "\n",
        "    rate = step_size\n",
        "    for e in range(0,epoch):\n",
        "      beta_t=beta\n",
        "      step_size=rate/(e+1)\n",
        "      start_time = time.time()\n",
        "      for k in range(0,N):\n",
        "          ub,uw = list(prev_ub),list(prev_uw)\n",
        "          n_w ,n_b =self.subtract_matrices(self.W,prev_uw,beta_t),self.subtract_matrices(self.b,prev_ub,beta_t)\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,n_w,n_b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "\n",
        "          for i in range(len(self.W)):\n",
        "            ub[i]= beta_t*prev_ub[i] + db[i]\n",
        "            uw[i]= beta_t*prev_uw[i] + dW[i]\n",
        "          self.b =self.subtract_matrices(self.b,ub,step_size)\n",
        "          self.W =self.subtract_matrices(self.W,uw,step_size)\n",
        "\n",
        "          prev_ub , prev_uw = list(ub),list(uw)\n",
        "      \n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "\n",
        "  def rmsprop(self,step_size,batch_size,epoch,beta=0.9,reg=0,epsilon=1e-10):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "\n",
        "    ub , uw =[],[]\n",
        "\n",
        "    for i in range(len(self.W)):\n",
        "      ub.append(np.zeros((self.b[i].shape[0],self.b[i].shape[1])))\n",
        "      uw.append(np.zeros((self.W[i].shape[0],self.W[i].shape[1])))\n",
        "\n",
        "\n",
        "    rate = step_size\n",
        "    for e in range(0,epoch):\n",
        "      step_size=rate/(e+1)\n",
        "      start_time = time.time()\n",
        "      beta_t,temp = self.update_beta(e+1,beta,0)\n",
        "      for k in range(0,N):\n",
        "         \n",
        "\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,self.W,self.b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "\n",
        "          for i in range(len(self.W)):\n",
        "            ub[i]= beta_t*ub[i] + (1-beta_t)*(db[i]**2)\n",
        "            uw[i]= beta_t*uw[i] + (1-beta_t)*(dW[i]**2)\n",
        "          \n",
        "          for i in range(len(self.W)):\n",
        "            result_b = self.b[i] - step_size*db[i]/(np.sqrt(ub[i])+epsilon)\n",
        "            result_w = self.W[i] - step_size*dW[i]/(np.sqrt(uw[i])+epsilon)\n",
        "            self.b[i]=result_b\n",
        "            self.W[i]=result_w\n",
        "\n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "      \n",
        "  \n",
        "  def adam(self,step_size,batch_size,epoch,beta1=0.9,beta2=0.999,reg=0,epsilon=1e-4):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "    rate = step_size\n",
        "    vb , vw =[],[]\n",
        "\n",
        "    for i in range(len(self.W)):\n",
        "      vb.append(np.zeros((self.b[i].shape[0],self.b[i].shape[1])))\n",
        "      vw.append(np.zeros((self.W[i].shape[0],self.W[i].shape[1])))\n",
        "\n",
        "    mw=list(vw)\n",
        "    mb=list(vb)\n",
        "\n",
        "    \n",
        "    for e in range(0,epoch):\n",
        "      step_size=rate/(e+1)\n",
        "      beta1_t,beta2_t = beta1,beta2\n",
        "      \n",
        "      for k in range(0,N):\n",
        "         \n",
        "\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,self.W,self.b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "\n",
        "          for i in range(len(self.W)):\n",
        "            mw[i]=  beta1_t*mw[i] + (1-beta1_t)*dW[i]\n",
        "            mb[i]=  beta1_t*mb[i] + (1-beta1_t)*db[i]\n",
        "            vb[i]= beta2_t*vb[i] + (1-beta2_t)*db[i]**2\n",
        "            vw[i]= beta2_t*vw[i] + (1-beta2_t)*dW[i]**2\n",
        "\n",
        "            mw_hat=mw[i]/(1-np.power(beta1_t,e+1))\n",
        "            mb_hat=mb[i]/(1-np.power(beta1_t,e+1))\n",
        "            vw_hat=vw[i]/(1-np.power(beta2_t,e+1))\n",
        "            vb_hat=vb[i]/(1-np.power(beta2_t,e+1))\n",
        "          \n",
        "            result_b = self.b[i] - step_size*mb_hat/(np.sqrt(vb_hat)+epsilon)\n",
        "            result_w = self.W[i] - step_size*mw_hat/(np.sqrt(vw_hat)+epsilon)\n",
        "            self.b[i]=result_b\n",
        "            self.W[i]=result_w\n",
        "\n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "  \n",
        "  def nadam(self,step_size,batch_size,epoch,beta1=0.9,beta2=0.999,reg=0,epsilon=1e-4):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "    rate = step_size\n",
        "    vb , vw =[],[]\n",
        "\n",
        "    for i in range(len(self.W)):\n",
        "      vb.append(np.zeros((self.b[i].shape[0],self.b[i].shape[1])))\n",
        "      vw.append(np.zeros((self.W[i].shape[0],self.W[i].shape[1])))\n",
        "\n",
        "    mw=list(vw)\n",
        "    mb=list(vb)\n",
        "\n",
        "    \n",
        "    for e in range(0,epoch):\n",
        "      step_size=rate/(e+1)\n",
        "      beta1_t,beta2_t = beta1,beta2\n",
        "      start_time = time.time()\n",
        "      for k in range(0,N):\n",
        "         \n",
        "\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          A,H,y_hat=self.forward_pro(minibatch,self.W,self.b)\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "\n",
        "          for i in range(len(self.W)):\n",
        "            mw[i]=  beta1_t*mw[i] + (1-beta1_t)*dW[i]\n",
        "            mb[i]=  beta1_t*mb[i] + (1-beta1_t)*db[i]\n",
        "            vb[i]= beta2_t*vb[i] + (1-beta2_t)*db[i]**2\n",
        "            vw[i]= beta2_t*vw[i] + (1-beta2_t)*dW[i]**2\n",
        "\n",
        "            mw_hat=mw[i]/(1-np.power(beta1_t,e+1))\n",
        "            mb_hat=mb[i]/(1-np.power(beta1_t,e+1))\n",
        "            vw_hat=vw[i]/(1-np.power(beta2_t,e+1))\n",
        "            vb_hat=vb[i]/(1-np.power(beta2_t,e+1))\n",
        "          \n",
        "            result_w = self.W[i] -(step_size/np.sqrt(vw_hat+epsilon))*(beta1_t*mw_hat+(1-beta1_t)*dW[i]/(1-beta1_t**(e+1)))\n",
        "            result_b = self.b[i] -(step_size/np.sqrt(vb_hat+epsilon))*(beta1_t*mb_hat+(1-beta1_t)*db[i]/(1-beta1_t**(e+1)))\n",
        "            self.b[i]=result_b\n",
        "            self.W[i]=result_w\n",
        "      \n",
        "\n",
        "      A,H,y_hat=self.forward_pro(self.validation_data,self.W,self.b)\n",
        "      A,H,train_hat=self.forward_pro(self.train_data,self.W,self.b)\n",
        "      validation_loss = 0\n",
        "      train_loss=0\n",
        "      if(self.loss==\"cross_entropy\"):\n",
        "        validation_loss=self.cross_entropy(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      if(self.loss==\"MSE\"):\n",
        "        validation_loss=self.mean_squared_error(y_hat,self.validation_label)\n",
        "        train_loss= self.cross_entropy(train_hat,self.train_label)\n",
        "      train_acc = self.accuracy(self.validation_data,self.validation_label)\n",
        "\n",
        "      validation_accuracy =self.accuracy(self.validation_data,self.validation_label)\n",
        "      wandb.log({\"validation_accuracy\": validation_accuracy})\n",
        "      wandb.log({\"validation_loss\": validation_loss})  \n",
        "      wandb.log({\"train_accuracy\":train_acc})\n",
        "      wandb.log({\"training_loss\":train_loss})\n",
        "\n",
        "\n",
        "  def activation_fun(self,matrix):\n",
        "      if(self.activation==\"sigmoid\"):\n",
        "        return self.sigmoid(matrix)\n",
        "      if(self.activation==\"tanh\"):\n",
        "        return self.tanh(matrix)\n",
        "      if(self.activation==\"ReLU\"):\n",
        "        return self.relu(matrix)\n",
        "  \n",
        "  def activation_derivative(self,matrix):\n",
        "      if(self.activation==\"sigmoid\"):\n",
        "        return self.sigmoid_derivative(matrix)\n",
        "      if(self.activation==\"tanh\"):\n",
        "        return self.tanh_derivative(matrix)\n",
        "      if(self.activation==\"ReLU\"):\n",
        "        return self.relu_derivative(matrix)\n",
        "\n",
        "     \n",
        "      \n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ZgkBC9_bGE",
        "outputId": "1372e302-b2c6-4e79-dc87-60d243af09db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08944360140849746\n",
            "0.08877487179799161\n",
            "0.08816616170370978\n",
            "0.08771390807562608\n",
            "0.08738072323184945\n",
            "0.08712125932820067\n",
            "0.08690962166588456\n",
            "0.0867326228289322\n",
            "0.08658162683772216\n",
            "0.08645049639826634\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Question.4**"
      ],
      "metadata": {
        "id": "57JWtdByTpyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aysDESkXrvaz"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \n",
        "\n",
        "    \"method\": 'random',\n",
        "    \"metric\":{\n",
        "        'name':'accuracy',\n",
        "        'goal':'maximize'\n",
        "    },\n",
        "    'parameters' :{\n",
        "        \"weight_init\" :{\"values\":[\"random\",\"Xavier\"]},\n",
        "        \"hidden_layers\": {\"values\": [ 3,4,5,6]},\n",
        "        \"size_of_layer\": {\"values\": [ 32, 64,128]},\n",
        "        \"activation\": {\"values\": [\"sigmoid\", \"reLU\",\"tanh\"]},\n",
        "        \"optimizer\": {\"values\": [\"sgd\",\"momentum\",\"nesterov\", \"adam\",\"rmsprop\",\"nadam\"]},\n",
        "        \"learning_rate\": {\"values\": [0.001,0.0001,0.00001]},\n",
        "        \"epoch\": {\"values\": [5,10]},\n",
        "        \"batch_size\": {\"values\": [16,32,64]},\n",
        "        \"weight_decay\": {\"values\": [0.0005, 0.005, 0.05]}\n",
        "    }\n",
        "    \n",
        "}\n",
        "Net = neural_network()\n",
        "def train_nn():\n",
        "\n",
        "    config_default={\n",
        "    'weight_init':\"random\",\n",
        "    'hidden_layers':3,\n",
        "    'size_of_layer':32,\n",
        "    'activation':\"sigmoid\",\n",
        "    'optimizer':\"sgd\",\n",
        "    'learning_rate':0.01,\n",
        "    'epoch':10,\n",
        "    'batch_size':32,\n",
        "    'weight_decay':0\n",
        "    }\n",
        "    \n",
        "   \n",
        "    wandb.init(config=config_default)\n",
        "    config = wandb.config\n",
        "    name='init_'+str(config.weight_init)+'_hl_'+str(config.hidden_layers)+\"_SL_\"+str(config.size_of_layer)+'_BS_'+str(config.batch_size)+\"_LR_\"+str(config.learning_rate)+'_AF_'+str(config.activation)+'_OPT_'+str(config.optimizer)+'_epoch_'+str(config.epoch)\n",
        "    wandb.init(name=name)\n",
        "    \n",
        "    Net.train(epoch=config.epoch, hidden_layers=config.hidden_layers, size_of_layer=config.size_of_layer, batch_size=config.batch_size, activation=config.activation, optimizer=config.optimizer, weight_init=config.weight_init, learning_rate=config.learning_rate, weight_decay=config.weight_decay)\n",
        "    accuracy = Net.accuracy(Net.test_data,Net.test_labels)\n",
        "    wandb.log({\"testing_accuracy\": accuracy})\n",
        "    y_pred=Net.predict(Net.test_data)\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(Net.test_labels, y_pred)\n",
        "\n",
        "    # Log confusion matrix to wandb\n",
        "    wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(probs=None,\n",
        "                                                y_true=Net.test_labels,\n",
        "                                                preds=y_pred,\n",
        "                                                class_names=titles,\n",
        "                                                title=\"Confusion matrix\")})\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project = \"March-10\",)\n",
        "wandb.agent(sweep_id, function = train_nn)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AMNO9uX-Kx_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiGn9L4YOzYT2NaHJMqlXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}