{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46249d03",
   "metadata": {
    "id": "_3U0YmtUF9vt",
    "papermill": {
     "duration": 0.013046,
     "end_time": "2023-05-21T04:32:55.248992",
     "exception": false,
     "start_time": "2023-05-21T04:32:55.235946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54bfe36d",
   "metadata": {
    "id": "2tFF0DGLvj3X",
    "papermill": {
     "duration": 0.012541,
     "end_time": "2023-05-21T04:32:55.273837",
     "exception": false,
     "start_time": "2023-05-21T04:32:55.261296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Importing Wandb and Login using Key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78456899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:32:55.302279Z",
     "iopub.status.busy": "2023-05-21T04:32:55.301520Z",
     "iopub.status.idle": "2023-05-21T04:33:10.634300Z",
     "shell.execute_reply": "2023-05-21T04:33:10.633342Z"
    },
    "id": "yvQ1-iNkFlwA",
    "papermill": {
     "duration": 15.350491,
     "end_time": "2023-05-21T04:33:10.636765",
     "exception": false,
     "start_time": "2023-05-21T04:32:55.286274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login(key =\"9c0cf96a5b886197f51883781f17b735b2ac32b1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04f824b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:10.664347Z",
     "iopub.status.busy": "2023-05-21T04:33:10.663483Z",
     "iopub.status.idle": "2023-05-21T04:33:10.667750Z",
     "shell.execute_reply": "2023-05-21T04:33:10.666972Z"
    },
    "id": "U95DxTfDMKru",
    "outputId": "a347a68a-cd2b-4c01-8678-37cfec1339d5",
    "papermill": {
     "duration": 0.02021,
     "end_time": "2023-05-21T04:33:10.669732",
     "exception": false,
     "start_time": "2023-05-21T04:33:10.649522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !wget 'https://drive.google.com/uc?export=download&id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw' -O dataset.zip && unzip dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4812ec",
   "metadata": {
    "id": "kKgKFY30wEV_",
    "papermill": {
     "duration": 0.012053,
     "end_time": "2023-05-21T04:33:10.694711",
     "exception": false,
     "start_time": "2023-05-21T04:33:10.682658",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f6bfe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:10.720586Z",
     "iopub.status.busy": "2023-05-21T04:33:10.720252Z",
     "iopub.status.idle": "2023-05-21T04:33:14.427513Z",
     "shell.execute_reply": "2023-05-21T04:33:14.426555Z"
    },
    "id": "qmUxkf-yNth3",
    "papermill": {
     "duration": 3.723273,
     "end_time": "2023-05-21T04:33:14.430151",
     "exception": false,
     "start_time": "2023-05-21T04:33:10.706878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d073539",
   "metadata": {
    "id": "EAedH9EWwOXo",
    "papermill": {
     "duration": 0.012473,
     "end_time": "2023-05-21T04:33:14.455104",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.442631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0121d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.480883Z",
     "iopub.status.busy": "2023-05-21T04:33:14.480342Z",
     "iopub.status.idle": "2023-05-21T04:33:14.594174Z",
     "shell.execute_reply": "2023-05-21T04:33:14.592463Z"
    },
    "id": "WitHN9dewVfp",
    "outputId": "462c9900-9afc-4c01-f357-825eba985a95",
    "papermill": {
     "duration": 0.12909,
     "end_time": "2023-05-21T04:33:14.596222",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.467132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#-----------------------Initialize Device---------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "print(device)\n",
    "\n",
    "\n",
    "#---------------------Start Seed------------------------------------\n",
    "\n",
    "import os\n",
    "def seed_everything(seed=1):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d43019",
   "metadata": {
    "id": "KySyue9jwrYz",
    "papermill": {
     "duration": 0.012955,
     "end_time": "2023-05-21T04:33:14.621783",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.608828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encode Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b2e225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.648558Z",
     "iopub.status.busy": "2023-05-21T04:33:14.648217Z",
     "iopub.status.idle": "2023-05-21T04:33:14.670083Z",
     "shell.execute_reply": "2023-05-21T04:33:14.669227Z"
    },
    "id": "N3HJM787wp8O",
    "papermill": {
     "duration": 0.037483,
     "end_time": "2023-05-21T04:33:14.672047",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.634564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.char2index = {'#': 0, '$': 1, '^': 2}\n",
    "        self.char2count = {'#': 1, '$': 1, '^': 1}\n",
    "        self.index2char = {0: '#', 1: '$', 2: '^'}\n",
    "        self.n_chars = 3  # Count\n",
    "        self.data = {}\n",
    "        \n",
    "\n",
    "    def addWord(self, word):\n",
    "        for char in word:\n",
    "            self.addChar(char)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class EncodedData:\n",
    "  def __init__(self,lang):\n",
    "    \n",
    "    #------------------------------------For Kaggle interFace---------------------------------\n",
    "\n",
    "    self.train_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_train.csv\", header = None)\n",
    "    self.val_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_valid.csv\", header = None)\n",
    "    self.test_df = pd.read_csv(f\"/kaggle/input/dlassgn/hin_test.csv\", header = None)\n",
    "\n",
    "    #------------------------------------For colab interface-------------------------------------\n",
    "\n",
    "#     self.train_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_train.csv\", header = None)\n",
    "#     self.val_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_valid.csv\", header = None)\n",
    "#     self.test_df = pd.read_csv(f\"drive/MyDrive/aksharantar_sampled/{lang}/{lang}_test.csv\", header = None)\n",
    "\n",
    "\n",
    "    self.input_lang = Lang('eng')\n",
    "    self.output_lang = Lang(lang)\n",
    "\n",
    "    # add the words to the respective languages\n",
    "    for i in range(len(self.train_df)):\n",
    "        \n",
    "        self.input_lang.addWord(self.train_df[0][i])\n",
    "        self.output_lang.addWord(self.train_df[1][i])\n",
    "    \n",
    "    max_len_1,max_len_2 = self.max_word_lengths(self.train_df)\n",
    "    self.train_xE,self.train_yE = self.preprocessing(self.train_df,max_len_1,max_len_2)\n",
    "\n",
    "    max_len_1,max_len_2 = self.max_word_lengths(self.val_df)\n",
    "    self.val_xE,self.val_yE = self.preprocessing(self.val_df,max_len_1,max_len_2)\n",
    "\n",
    "    max_len_1,max_len_2 = self.max_word_lengths(self.test_df)\n",
    "    self.test_xE,self.test_yE = self.preprocessing(self.test_df,max_len_1,max_len_2)\n",
    "\n",
    "    \n",
    "  #-------------------Calculate max length of word in input and output----------\n",
    "\n",
    "  def max_word_lengths(self,df):\n",
    "    max_len_1 = df.iloc[:,0].str.len().max()\n",
    "    max_len_2 = df.iloc[:,1].str.len().max()\n",
    "    return max_len_1, max_len_2\n",
    "\n",
    "\n",
    "  #-----------------Preprocess on input and output------------------------------\n",
    "\n",
    "  def preprocessing(self,df,max_len_1,max_len_2):\n",
    "    \n",
    "    M1 = np.zeros((len(df),max_len_1+1))\n",
    "    M2 = np.zeros((len(df),max_len_2+2))\n",
    "\n",
    "    \n",
    "    \n",
    "    # ---------------------------Encode column 1-------------------------------\n",
    "\n",
    "    col1 = df.iloc[:, 0].str.lower().str.split()\n",
    "\n",
    "    for i in range(len(col1)) :\n",
    "      word = col1[i][0]\n",
    "      # print(word,\" \" ,word[0],word[1])\n",
    "      for j in range(len(word)):\n",
    "        char =word[j]\n",
    "        if(self.input_lang.char2index.get(char) is not None):\n",
    "          M1[i][j]=self.input_lang.char2index.get(char)\n",
    "        else:\n",
    "          M1[i][j]=1\n",
    "    \n",
    "    # -----------------------Encode column 2-----------------------------------\n",
    "\n",
    "    col2 = df.iloc[:, 1].str.lower().str.split()\n",
    "\n",
    "    for i in range(len(col2)) :\n",
    "\n",
    "\n",
    "      word = col2[i][0]\n",
    "  \n",
    "      M2[i][0]=2\n",
    "      for j in range(len(word)):\n",
    "        char =word[j]\n",
    "        if(self.output_lang.char2index.get(char) is not None):\n",
    "          M2[i][j+1]=self.output_lang.char2index.get(char)\n",
    "        else:\n",
    "          M2[i][j+1]=1\n",
    "\n",
    "    \n",
    "    return torch.from_numpy(M1),torch.from_numpy(M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40d34a",
   "metadata": {
    "id": "MxPVr0Vyyg8Y",
    "papermill": {
     "duration": 0.012026,
     "end_time": "2023-05-21T04:33:14.696525",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.684499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EncoderRNN DecoderRNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab64bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.722661Z",
     "iopub.status.busy": "2023-05-21T04:33:14.722353Z",
     "iopub.status.idle": "2023-05-21T04:33:14.740891Z",
     "shell.execute_reply": "2023-05-21T04:33:14.739915Z"
    },
    "id": "niDMJ5JTab-h",
    "papermill": {
     "duration": 0.03445,
     "end_time": "2023-05-21T04:33:14.743193",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.708743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, num_encoders, hidden_size, bidirectional=False, cell='GRU',dropout=0.0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_encoders = num_encoders\n",
    "        self.bidirectional = bidirectional\n",
    "        self.cell = cell\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #----------------------RNN----------------------------------------------\n",
    "        if self.cell == 'RNN':\n",
    "            self.encoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_encoders,\n",
    "                                      bidirectional=bidirectional )\n",
    "        \n",
    "        #----------------------GRU----------------------------------------------\n",
    "        elif self.cell == 'GRU':\n",
    "            self.encoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_encoders,\n",
    "                                      bidirectional=bidirectional)\n",
    "\n",
    "        #----------------------LSTM---------------------------------------------\n",
    "        else:\n",
    "            self.encoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_encoders,\n",
    "                                       bidirectional=bidirectional )\n",
    "            \n",
    "    #-------------------------initialize hidden layer---------------------------\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "      \n",
    "        #------------------------Number of directions---------------------------\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "\n",
    "        #------------------------initialize Hidden Layer------------------------\n",
    "        if self.cell == 'LSTM':\n",
    "            return (torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device),\n",
    "                    torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device))\n",
    "        else:\n",
    "          return torch.zeros(self.num_encoders * num_directions, batch_size, self.hidden_size, device=device)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        batch_size = input_seq.size(1)\n",
    "        \n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(input_seq.long())\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        # Encoder layers\n",
    "        encoder_hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        # print(encoder_hidden.shape)\n",
    "        if self.cell == 'LSTM':\n",
    "            (encoder_hidden,encoder_cell) = self.init_hidden(batch_size)\n",
    "            encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder_rnn(embedded, (encoder_hidden, encoder_cell))\n",
    "            encoder_hidden = (encoder_hidden,encoder_cell)\n",
    "        else:\n",
    "          \n",
    "          encoder_outputs, encoder_hidden = self.encoder_rnn(embedded, encoder_hidden)\n",
    "        \n",
    "        \n",
    "        return  encoder_outputs,encoder_hidden\n",
    "\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, num_encoders, num_decoders, hidden_size, dropout=0.0, cell='GRU'):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_encoders = num_encoders\n",
    "        self.num_decoders = num_decoders\n",
    "        self.cell = cell\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        #------Initialize Dropout , decoder_fc(out),softmax function------------\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.decoder_fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        #-----------------------Initialize Embedding layer----------------------\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        \n",
    "\n",
    "        if self.cell == 'RNN':\n",
    "            self.decoder_rnn = nn.RNN(embedding_size, hidden_size, num_layers=num_decoders)\n",
    "        elif self.cell == 'GRU':\n",
    "            self.decoder_rnn = nn.GRU(embedding_size, hidden_size, num_layers=num_decoders)\n",
    "                                      \n",
    "        else :\n",
    "            self.decoder_rnn = nn.LSTM(embedding_size, hidden_size, num_layers=num_decoders)                      \n",
    "                                     \n",
    "\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        batch_size = input_seq.shape[0]\n",
    "        \n",
    "\n",
    "        \n",
    "        decoder_input = input_seq\n",
    "\n",
    "        decoder_input = decoder_input.unsqueeze(1)\n",
    "        \n",
    "        # Embedding layer aaplying embedding and dropout\n",
    "\n",
    "        embedded = self.embedding(decoder_input.long()).view(-1,batch_size,self.embedding_size)\n",
    "        # embedded = self.dropout(embedded)\n",
    "        decoder_hidden = hidden\n",
    "\n",
    "        decoder_output , decoder_hidden = self.decoder_rnn(embedded, decoder_hidden)\n",
    "       \n",
    "        # Project the output to the output size and apply softmax\n",
    "\n",
    "        decoder_output = self.softmax(self.decoder_fc(decoder_output))\n",
    "        \n",
    "        # Return the output tensor\n",
    "        return decoder_output,decoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c20beb",
   "metadata": {
    "id": "SzyQmkL-ggZF",
    "papermill": {
     "duration": 0.012385,
     "end_time": "2023-05-21T04:33:14.767893",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.755508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76c0a79",
   "metadata": {
    "id": "-wT2xoC8aoLL",
    "papermill": {
     "duration": 0.012379,
     "end_time": "2023-05-21T04:33:14.792668",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.780289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training and Evalution Function for normal decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0de9432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.819315Z",
     "iopub.status.busy": "2023-05-21T04:33:14.819002Z",
     "iopub.status.idle": "2023-05-21T04:33:14.852284Z",
     "shell.execute_reply": "2023-05-21T04:33:14.851453Z"
    },
    "id": "9U4LPaXOcE56",
    "papermill": {
     "duration": 0.049359,
     "end_time": "2023-05-21T04:33:14.854228",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.804869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#---------Train Seq2Seq Model--------------------------\n",
    "\n",
    "def trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio):\n",
    "\n",
    "  # input vocabaliry size\n",
    "  input_size = data.input_lang.n_chars\n",
    "\n",
    "  # output vocabaliry size\n",
    "  output_size = data.output_lang.n_chars\n",
    "\n",
    "  # Initialize Encoder , Decoder\n",
    "  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n",
    "  decoder = DecoderRNN(output_size,embedding_size,num_encoder,num_decoder,hidden_size,dropout,cell_type)\n",
    "\n",
    "  # Load Data into DataLoader\n",
    "  trainData = TensorDataset(data.train_xE, data.train_yE)\n",
    "  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n",
    "\n",
    "  # Initialize Encoder Decoder optimizer and loss function\n",
    "  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
    "  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
    "  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "  # Push encoder and decoder to device\n",
    "  encoder.to(device)\n",
    "  decoder.to(device)\n",
    "\n",
    "  seq_len = 20\n",
    "  for i in range(epoch):\n",
    "  \n",
    "    running_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    # Set Encoder and Decoder in Train mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # forward pass and backtrack for each batch\n",
    "\n",
    "    for j,(train_x,train_y) in enumerate(trainLoader):\n",
    "        loss=0\n",
    "\n",
    "        seq_len = train_y.shape[1]\n",
    "\n",
    "        # Load data to device\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "        \n",
    "        x = train_x.T\n",
    "        y = train_y.T\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Encoder forward Pass\n",
    "        encoder_output, encoder_hidden = encoder(x)\n",
    "        \n",
    "\n",
    "        # handle bidirectional case \n",
    "        if bidirectional:\n",
    "          if(cell_type==\"LSTM\"):\n",
    "            hidden,state = encoder_hidden\n",
    "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            state=torch.add(state[0],state[1])/2\n",
    "            encoder_hidden =(hidden,state)\n",
    "\n",
    "          else:\n",
    "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "        decoder_input =(y)[0]\n",
    "        \n",
    "        # handle layers mismatch\n",
    "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
    "\n",
    "        # pred_probabilities of batch\n",
    "        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n",
    "          \n",
    "        \n",
    "        for k in range(1,y.shape[0]):\n",
    "\n",
    "          # Decoder Pass\n",
    "          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "          \n",
    "          pred_output[k-1]=decoder_output\n",
    "\n",
    "          # Get the index of the maximum probability in each row\n",
    "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
    "\n",
    "          \n",
    "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
    "          indices = indices.view(batch_size)\n",
    "          \n",
    "\n",
    "          # teach forcing algorithm\n",
    "          if((random.random()<teach_ratio)):\n",
    "            decoder_input=(y)[k]\n",
    "          else:\n",
    "            decoder_input=indices.clone()\n",
    "\n",
    "        # Decoder forward pass\n",
    "        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "          \n",
    "        pred_output[-1]=decoder_output\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Calculate max probalibity index and load it to device \n",
    "        preds = pred_output.argmax(dim=-1)\n",
    "        preds = preds.T\n",
    "        preds = preds.to(device)\n",
    "        \n",
    "        # Reshape tensors\n",
    "        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_fun(pred_output, y.long())\n",
    "        \n",
    "        # add loss for each batch\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "\n",
    "        # Compute the gradients and update the parameters\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "       \n",
    "        # Calculate correct words in each batch\n",
    "        train_correct += count_exact_matches(preds,train_y)\n",
    "\n",
    "    # calculate AVg_accuracy and avg_loss      \n",
    "    avg_loss = running_loss / (batch_size * len(trainLoader)*seq_len)\n",
    "    avg_acc = train_correct/(batch_size*len(trainLoader))\n",
    "\n",
    "        \n",
    "    #calculate validation accuracy and loss for each epoch and log all parameters to waandb\n",
    "    val_loss,val_acc ,preds= evaluate(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc*100})\n",
    "  return encoder ,decoder\n",
    "\n",
    "\n",
    "#----------------------------------evaluate on data loss and accuracy-----------\n",
    "\n",
    "def evaluate(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n",
    "\n",
    "    # Set ENCODER and Decoder in evalution Mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    #predictions for whole Dataset\n",
    "\n",
    "    predicted = None\n",
    "    running_loss =0\n",
    "    correct=0\n",
    "    total=0\n",
    "    Data = TensorDataset(X,Y)\n",
    "    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n",
    "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    with torch.no_grad():\n",
    "      for j,(xx,yy) in enumerate(Loader):\n",
    "        loss=0\n",
    "\n",
    "        # Push batch to Device\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "\n",
    "        x = xx.transpose(0,1)\n",
    "        y = yy.transpose(0,1)\n",
    "\n",
    "        # Encoder forward pass\n",
    "        encoder_output, encoder_hidden = encoder(x)\n",
    "        \n",
    "        # handle bidirectional case and LSTM cell type\n",
    "        if bidirectional:\n",
    "          if(cell_type==\"LSTM\"):\n",
    "            hidden,state = encoder_hidden\n",
    "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            state=torch.add(state[0],state[1])/2\n",
    "            encoder_hidden =(hidden,state)\n",
    "\n",
    "          else:\n",
    "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "        # Initialize the decoder_hidden tensor\n",
    "          \n",
    "        \n",
    "        \n",
    "        decoder_input =(y)[0]\n",
    "        # print(\"encoder_hidden:-\",encoder_hidden.shape)\n",
    "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
    "        \n",
    "        pred_output=torch.zeros(y.shape[0],batch_size,output_size)\n",
    "          \n",
    "\n",
    "        # Decoding for one batch\n",
    "        for k in range(1,y.shape[0]):\n",
    "\n",
    "          \n",
    "          decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "          \n",
    "          pred_output[k-1]=decoder_output\n",
    "\n",
    "          # Get the index of the maximum probability in each row\n",
    "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
    "\n",
    "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
    "          indices = indices.view(batch_size)\n",
    "          decoder_input=indices.clone()\n",
    "\n",
    "        decoder_output,decoder_hidden= decoder(decoder_input, decoder_hidden) \n",
    "        pred_output[-1]=decoder_output\n",
    "\n",
    "        preds = pred_output.argmax(dim=-1)\n",
    "        preds = preds.T\n",
    "        \n",
    "        # Concat for whole dataSet\n",
    "        if(predicted==None):\n",
    "          predicted = preds\n",
    "        else:\n",
    "          predicted = torch.cat([predicted,preds],dim=0)\n",
    "        \n",
    "        # Reshape to (batch_size * seq_len, vocab_size) and Load to device\n",
    "        pred_output= pred_output.view(-1, pred_output.size(-1))  \n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        pred_output = pred_output.to(device)\n",
    "        y =y.to(device)\n",
    "\n",
    "        # Calculate  Loss\n",
    "        loss = loss_fun(pred_output, y.long())\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate correct predictions\n",
    "        correct += count_exact_matches(preds,yy)\n",
    "        \n",
    "    # Loss and Accuracy for Dataset    \n",
    "    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size)*Y.shape[1])\n",
    "    avg_acc = correct / X.shape[0]\n",
    "    \n",
    "    return avg_loss , avg_acc , predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c233cd7",
   "metadata": {
    "id": "L-Po5pDgcOFC",
    "papermill": {
     "duration": 0.012209,
     "end_time": "2023-05-21T04:33:14.879309",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.867100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Supporting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77c68757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.908135Z",
     "iopub.status.busy": "2023-05-21T04:33:14.907209Z",
     "iopub.status.idle": "2023-05-21T04:33:14.927673Z",
     "shell.execute_reply": "2023-05-21T04:33:14.926775Z"
    },
    "id": "Pwoce_8XKBhY",
    "papermill": {
     "duration": 0.037607,
     "end_time": "2023-05-21T04:33:14.929806",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.892199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# -------------------Count Number of correct words------------------------------\n",
    "\n",
    "def count_exact_matches(pred, target):\n",
    "    \"\"\"\n",
    "    Counts the number of rows in preds tensor that match exactly with each row in y tensor.\n",
    "    preds: tensor of shape (batch_size, seq_len)\n",
    "    y: tensor of shape (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    pred = pred[:, 1:-1] # ignore first and last index of each row\n",
    "    target = target[:, 1:-1] # ignore first and last index of each row\n",
    "    count=0;\n",
    "    for i in range(pred.shape[0]):\n",
    "      flag = True\n",
    "      for j in range(target.shape[1]):\n",
    "        if(target[i][j].item()!=0 and target[i][j].item()!=pred[i][j].item()):\n",
    "          flag=False\n",
    "          break;\n",
    "         \n",
    "      if(flag):\n",
    "        # print(\"---------Correct-----\")\n",
    "        # print(pred[i])\n",
    "        # print(target[i])\n",
    "        count+=1;\n",
    "    # print(count)\n",
    "    return count\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#------------------------------ Confusion Matrix creation----------------------- \n",
    "\n",
    "def confusion_matrix (predicted , target , output_dict_size):\n",
    "  '''Create Confusion matrix of shape output_dict_size\n",
    "     and return it'''\n",
    "  CM = np.zeros((output_dict_size,output_dict_size))\n",
    "\n",
    "  for i in range(target.shape[0]):\n",
    "    for j in range(target.shape[1]):\n",
    "       pred = int(predicted[i][j])\n",
    "       targ = int(target[i][j])\n",
    "       CM[pred][targ]+=1\n",
    "  \n",
    "  return CM\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,vocab):\n",
    "\n",
    "\n",
    "  # This code will plot Confusion matrix\n",
    "\n",
    "\n",
    "  classes =[]\n",
    "\n",
    "  for i in range(cm.shape[0]):\n",
    "    classes.append(vocab[i])\n",
    "\n",
    "  print(classes)\n",
    "  # Calculate the percentages\n",
    "  percentages = (cm / np.sum(cm)) * 100\n",
    "\n",
    "  # Define the text for each cell\n",
    "  cell_text = []\n",
    "  for i in range(len(classes)):\n",
    "      row_text = []\n",
    "      for j in range(len(classes)):\n",
    "\n",
    "          txt = \"Total \"+f'{cm[i, j]}Per. ({percentages[i, j]:.3f})'\n",
    "          if(i==j):\n",
    "            txt =\"Correcty Predicted \" +classes[i]+\"\"+txt\n",
    "          if(i!=j):\n",
    "            txt =\"Predicted \" +classes[j]+\" For \"+classes[i]+\"\"+txt\n",
    "          row_text.append(txt)\n",
    "      cell_text.append(row_text)\n",
    "\n",
    "  # Define the trace\n",
    "  trace = go.Heatmap(z=percentages,\n",
    "                    x=classes,\n",
    "                    y=classes,\n",
    "                    colorscale='Blues',\n",
    "                    colorbar=dict(title='Percentage'),\n",
    "                    hovertemplate='%{text}%',\n",
    "                    text=cell_text,\n",
    "                    )\n",
    "\n",
    "  # Define the layout\n",
    "  layout = go.Layout(title='Confusion Matrix',\n",
    "                    xaxis=dict(title='Predicted Character'),\n",
    "                    yaxis=dict(title='True Character'),\n",
    "                    )\n",
    "\n",
    "  # Plot the figure\n",
    "  fig = go.Figure(data=[trace], layout=layout)\n",
    "  return fig\n",
    "  #wandb.log({'confusion_matrix': (fig)})\n",
    "\n",
    "\n",
    "# Generate Decoder hidden layer according to number of decoder and decoder and cell_type\n",
    " \n",
    "\n",
    "def generateDecoderHidden(cell,num_encoder,num_decoder,encoder_hidden):\n",
    "    hidden={}\n",
    "\n",
    "    # ------------For LSTM cell Type--------------------\n",
    "\n",
    "    if(cell==\"LSTM\"):\n",
    "      \n",
    "      hx,state = (encoder_hidden)\n",
    "\n",
    "      # number of encoder > number of decoder\n",
    "\n",
    "      if(num_encoder>num_decoder):\n",
    "        hx = hx[num_encoder-num_decoder:]\n",
    "        state = state[num_encoder-num_decoder:]\n",
    "      \n",
    "      # number of encoder < number of decoder\n",
    "\n",
    "      elif(num_encoder<num_decoder):\n",
    "        top = hx[-1].unsqueeze(0).clone()\n",
    "        extra = num_decoder-num_encoder\n",
    "        hiddenExtra =top.repeat(extra,1,1)\n",
    "        hx =torch.cat((hx,hiddenExtra),dim=0)\n",
    "      \n",
    "        stop = state[-1].unsqueeze(0).clone()\n",
    "        extra = num_decoder-num_encoder\n",
    "        stateExtra =top.repeat(extra,1,1)\n",
    "        state =torch.cat((state,stateExtra),dim=0)\n",
    "\n",
    "      hidden=(hx,state)\n",
    "\n",
    "    # -------------------For Other cell type--------\n",
    "\n",
    "    else :\n",
    "\n",
    "      hidden = encoder_hidden\n",
    "      \n",
    "      # number of encoder > number of decoder\n",
    "      if(num_encoder>num_decoder):\n",
    "        hidden = encoder_hidden[num_encoder-num_decoder:]\n",
    "\n",
    "      # number of encoder < number of decoder \n",
    "      elif(num_encoder<num_decoder):\n",
    "        top = encoder_hidden[-1].unsqueeze(0).clone()\n",
    "        extra = num_decoder-num_encoder\n",
    "        hiddenExtra =top.repeat(extra,1,1)\n",
    "        hidden =torch.cat((encoder_hidden,hiddenExtra),dim=0)\n",
    "\n",
    "    return hidden\n",
    "\n",
    "\n",
    "\n",
    "# test_loss,test_acc,preds = evaluate(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,len(data.test_xE),bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "\n",
    "# print(test_loss , test_acc)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4b374",
   "metadata": {
    "id": "gtY8dMX_yxvW",
    "papermill": {
     "duration": 0.012528,
     "end_time": "2023-05-21T04:33:14.955233",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.942705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Attention Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc1ea6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:14.981613Z",
     "iopub.status.busy": "2023-05-21T04:33:14.981317Z",
     "iopub.status.idle": "2023-05-21T04:33:14.995094Z",
     "shell.execute_reply": "2023-05-21T04:33:14.994223Z"
    },
    "id": "9deGoZpu4y25",
    "papermill": {
     "duration": 0.02946,
     "end_time": "2023-05-21T04:33:14.997010",
     "exception": false,
     "start_time": "2023-05-21T04:33:14.967550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding_size , output_size, num_decoder, cell_type, dropout=0.0):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "\n",
    "        # Define the input size, hidden size, output size, and number of layers\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_decoder\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Define the embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Define the attention mechanism\n",
    "        self.attention = nn.Linear(hidden_size + embedding_size, hidden_size)\n",
    "        self.context_vector = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.energy = nn.Linear(hidden_size * 2, 1)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "        # Define the output layer and relu\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "         # Define the dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Define softmax\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        # Define the RNN layer\n",
    "        if cell_type == \"RNN\":\n",
    "            self.decoder_rnn = nn.RNN(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
    "        elif cell_type == \"GRU\":\n",
    "            self.decoder_rnn = nn.GRU(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
    "        elif cell_type == \"LSTM\":\n",
    "            self.decoder_rnn = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers=num_decoder)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell type\")\n",
    "\n",
    "       \n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "\n",
    "        # Convert to [1,batch_size] \n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        seq_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        # Embedding layer and Dropout\n",
    "        embedding = self.embedding(input.long())\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        cell=None\n",
    "        if(self.cell_type==\"LSTM\"):\n",
    "          hidden ,cell= hidden \n",
    "       \n",
    "        hidden_new= hidden.repeat(seq_len, 1,  1)  # repeat along the new dimension\n",
    "\n",
    "        #-------------------------Attention Mechanism---------------------------\n",
    "        energy = self.relu(self.energy(torch.cat((hidden_new, encoder_outputs), dim=2)))\n",
    "        attention = self.softmax(energy)\n",
    "        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_outputs)\n",
    "        rnn_input = torch.cat((context_vector, embedding), dim=2)\n",
    "\n",
    "        if(self.cell_type==\"LSTM\"):\n",
    "          hidden = (hidden,cell)\n",
    "        \n",
    "        outputs, decoder_hidden= self.decoder_rnn(rnn_input, hidden)\n",
    "       \n",
    "        predictions = self.fc(outputs)\n",
    "       \n",
    "        output = self.logsoftmax(predictions)\n",
    "        \n",
    "        return output, decoder_hidden ,attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbaca5",
   "metadata": {
    "id": "pY-fsxn31k-v",
    "papermill": {
     "duration": 0.012333,
     "end_time": "2023-05-21T04:33:15.022099",
     "exception": false,
     "start_time": "2023-05-21T04:33:15.009766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Trainining of Attention decoder and evalution for Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac70745c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:15.049354Z",
     "iopub.status.busy": "2023-05-21T04:33:15.049050Z",
     "iopub.status.idle": "2023-05-21T04:33:15.084180Z",
     "shell.execute_reply": "2023-05-21T04:33:15.083353Z"
    },
    "id": "WMP8rrqG10pN",
    "papermill": {
     "duration": 0.051398,
     "end_time": "2023-05-21T04:33:15.086234",
     "exception": false,
     "start_time": "2023-05-21T04:33:15.034836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def trainAttension(data,cell_type=\"RNN\",embedding_size=64,num_encoder=2,num_decoder=2,hidden_size=32,batch_size=16,bidirectional=False,dropout=0.0,beam_width=0,epoch=10,learn_rate=0.001,teach_ratio=0.0):\n",
    "  \n",
    "  #input/output lang vocabalary size\n",
    "  input_size = data.input_lang.n_chars\n",
    "  output_size = data.output_lang.n_chars\n",
    "\n",
    "  # initialize encoder and AttentionDecoder\n",
    "  encoder = EncoderRNN( input_size, embedding_size, num_encoder, hidden_size, bidirectional, cell_type,dropout)\n",
    "  decoder = AttentionDecoderRNN(cell_type=cell_type,dropout=dropout,embedding_size=embedding_size,hidden_size=hidden_size,num_decoder=num_decoder,output_size=output_size)\n",
    "\n",
    "  # pushData to Loader with given batchSize\n",
    "  trainData = TensorDataset(data.train_xE, data.train_yE)\n",
    "  trainLoader = DataLoader(trainData,batch_size=batch_size,shuffle=True) \n",
    "\n",
    "  # Initialize optimizer and Loss Function\n",
    "  encoder_optimizer=optim.Adam(encoder.parameters(),learn_rate)\n",
    "  decoder_optimizer=optim.Adam(decoder.parameters(),learn_rate)\n",
    "  loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "  # push Encoder and decoder Device\n",
    "  encoder.to(device)\n",
    "  decoder.to(device)\n",
    "\n",
    "  seq_len = 20\n",
    "  for i in range(epoch):\n",
    "  \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    # Encoder , Decoder in Train Mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    for j,(train_x,train_y) in enumerate(trainLoader):\n",
    "        loss=0\n",
    "\n",
    "        # Seq_len of output\n",
    "        seq_len = train_y.shape[1]\n",
    "\n",
    "        # push batch to device\n",
    "        train_x = train_x.to(device)\n",
    "        train_y = train_y.to(device)\n",
    "\n",
    "        # transpose Batch dat\n",
    "        x = train_x.transpose(0, 1)\n",
    "        y = train_y.transpose(0, 1)\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # encoder forward pass\n",
    "        encoder_output, encoder_hidden = encoder(x)\n",
    "        \n",
    "\n",
    "        # Handle birectional and LSTM case\n",
    "        if bidirectional:\n",
    "          hidden_size = encoder_output.size(2) // 2\n",
    "          forward_output = encoder_output[:, :, :hidden_size]\n",
    "          backward_output = encoder_output[:, :, hidden_size:]\n",
    "          encoder_output = torch.add(forward_output, backward_output)/2\n",
    "\n",
    "          if(cell_type==\"LSTM\"):\n",
    "            hidden,state = encoder_hidden\n",
    "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            state=torch.add(state[0],state[1])/2\n",
    "            encoder_hidden =(hidden,state)\n",
    "\n",
    "          else:\n",
    "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "        # Initialize the decoder_hidden , decoder_input tensor\n",
    "          \n",
    "        \n",
    "        \n",
    "        decoder_input =(y)[0]\n",
    "        \n",
    "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
    "        \n",
    "        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n",
    "          \n",
    "        \n",
    "        for k in range(1,y.shape[0]):\n",
    "\n",
    "          \n",
    "          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n",
    "          \n",
    "          pred_output[k-1]=decoder_output\n",
    "\n",
    "          # Get the index of the maximum probability in each row\n",
    "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
    "\n",
    "         \n",
    "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
    "          indices = indices.view(batch_size)\n",
    "          \n",
    "          if((random.random()<teach_ratio)):\n",
    "            decoder_input=(y)[k]\n",
    "          else:\n",
    "            decoder_input=indices.clone()\n",
    "\n",
    "        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n",
    "        pred_output[-1]=decoder_output\n",
    "        \n",
    "        # get predicted indices (words for batch)\n",
    "        preds = pred_output.argmax(dim=-1)\n",
    "        preds = preds.T    #[batch_size , seq_len]\n",
    "        \n",
    "\n",
    "        pred_output= pred_output.view(-1, pred_output.size(-1))  # Reshape to (batch_size * seq_len, vocab_size)\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        \n",
    "        # compute loss\n",
    "        loss = loss_fun(pred_output, y.long())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute the gradients and update the parameters\n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        # Compute correct matches\n",
    "\n",
    "        correct += count_exact_matches(preds,train_y)\n",
    "       \n",
    "    # loss and accuracy for whole data    \n",
    "    avg_loss = running_loss / (batch_size * len(trainLoader)*seq_len)\n",
    "    avg_acc = correct/(batch_size*(len(trainLoader)))\n",
    "    \n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "            \n",
    "    val_loss,val_acc,preds = evaluateAttension(data.val_xE,data.val_yE,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "    wandb.log({'Train_loss': avg_loss, 'Train_acc': avg_acc*100,'Epoch':i+1,'Val_loss':val_loss,'Val_Acc':val_acc})\n",
    "  return encoder ,decoder\n",
    "\n",
    "\n",
    "\n",
    "def evaluateAttension(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n",
    "    \n",
    "    # Set encoder decoder in evalution Mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Initialize predicted , runningloss , correct ( predictions)\n",
    "    predicted=None\n",
    "    running_loss =0\n",
    "    correct=0\n",
    "    \n",
    "    # Load data into Loader and initialize loss function\n",
    "    Data = TensorDataset(X,Y)\n",
    "    Loader = DataLoader(Data,batch_size=batch_size,shuffle=False) \n",
    "    loss_fun=nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "    # Calculate loss for whole data and total correct predictions \n",
    "    with torch.no_grad():\n",
    "      for j,(xx,yy) in enumerate(Loader):\n",
    "        \n",
    "        #  push Batch to device\n",
    "        x = xx.to(device)\n",
    "        y = yy.to(device)\n",
    "\n",
    "        x = x.transpose(0,1)\n",
    "        y = y.transpose(0,1)\n",
    "\n",
    "        # Encoder forawrd pass\n",
    "        encoder_output, encoder_hidden = encoder(x)\n",
    "        \n",
    "        #handle bidirectional case\n",
    "        if bidirectional:\n",
    "          hidden_size = encoder_output.size(2) // 2\n",
    "          forward_output = encoder_output[:, :, :hidden_size]\n",
    "          backward_output = encoder_output[:, :, hidden_size:]\n",
    "          encoder_output = torch.add(forward_output, backward_output)/2\n",
    "\n",
    "          # print(hidden_size)\n",
    "          if(cell_type==\"LSTM\"):\n",
    "            hidden,state = encoder_hidden\n",
    "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            state=torch.add(state[0],state[1])/2\n",
    "            encoder_hidden =(hidden,state)\n",
    "\n",
    "          else:\n",
    "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "        # Initialize the decoder_hidden tensor and decoder_input\n",
    "        decoder_input =(y)[0]\n",
    "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
    "        \n",
    "        \n",
    "        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n",
    "        for k in range(1,y.shape[0]):\n",
    "\n",
    "          \n",
    "          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n",
    "          \n",
    "          pred_output[k-1]=decoder_output\n",
    "\n",
    "          # Get the index of the maximum probability in each row\n",
    "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
    "\n",
    "          \n",
    "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
    "          indices = indices.view(batch_size)\n",
    "          decoder_input=indices.clone()\n",
    "\n",
    "        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output) \n",
    "        pred_output[-1]=decoder_output\n",
    "       \n",
    "        \n",
    "        # Get predicted Words\n",
    "        preds = pred_output.argmax(dim=-1)\n",
    "        preds = preds.T\n",
    "\n",
    "        if(predicted==None):\n",
    "          predicted = preds\n",
    "        else:\n",
    "          predicted = torch.cat([predicted,preds],dim=0)\n",
    "        preds=preds.to(device)\n",
    "\n",
    "        # Reshape to (batch_size * seq_len, vocab_size)\n",
    "        pred_output= pred_output.view(-1, pred_output.size(-1))  \n",
    "        y = y.reshape(-1)\n",
    "        \n",
    "        # calculate loss and correct predictions for batch\n",
    "        loss = loss_fun(pred_output, y.long())\n",
    "        running_loss += loss.item()\n",
    "        correct += count_exact_matches(preds,yy)\n",
    "          \n",
    "        \n",
    "    avg_loss = running_loss / (batch_size * (X.shape[0]/batch_size)*Y.shape[1])\n",
    "  \n",
    "    avg_acc = 100*correct / X.shape[0]\n",
    "    \n",
    "    return avg_loss , avg_acc , predicted\n",
    "    \n",
    "# encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26d1cc",
   "metadata": {
    "id": "iF0W-_tHOcRU",
    "papermill": {
     "duration": 0.012225,
     "end_time": "2023-05-21T04:33:15.111065",
     "exception": false,
     "start_time": "2023-05-21T04:33:15.098840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Data for language \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7490bec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:15.137889Z",
     "iopub.status.busy": "2023-05-21T04:33:15.137114Z",
     "iopub.status.idle": "2023-05-21T04:33:18.492319Z",
     "shell.execute_reply": "2023-05-21T04:33:18.491440Z"
    },
    "id": "Fwv002S2J8ie",
    "papermill": {
     "duration": 3.371017,
     "end_time": "2023-05-21T04:33:18.494695",
     "exception": false,
     "start_time": "2023-05-21T04:33:15.123678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data = EncodedData(\"hin\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370376da",
   "metadata": {
    "id": "s4eLcOzNgVQI",
    "papermill": {
     "duration": 0.012381,
     "end_time": "2023-05-21T04:33:18.520022",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.507641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Wandb configuration for sweep runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6df151c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:18.546558Z",
     "iopub.status.busy": "2023-05-21T04:33:18.546252Z",
     "iopub.status.idle": "2023-05-21T04:33:18.560658Z",
     "shell.execute_reply": "2023-05-21T04:33:18.559837Z"
    },
    "id": "QxHRRcegcuMv",
    "papermill": {
     "duration": 0.029883,
     "end_time": "2023-05-21T04:33:18.562430",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.532547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wandb_runs(data):\n",
    "\n",
    "      #-------Wandb configurations--------\n",
    "\n",
    "    config = {\n",
    "        \"project\":\"CS6910_Assignment3_\",\n",
    "        \"method\": 'bayes',\n",
    "        \"metric\": {\n",
    "        'name': 'Val_Acc',\n",
    "        'goal': 'maximize'\n",
    "        },\n",
    "        'parameters' :{\n",
    "        \"epoch\": {\"values\":[30]},\n",
    "        \"learn_rate\": {\"values\":[0.001]},\n",
    "        \"batch_size\": {\"values\": [256,64,32]},\n",
    "        \"embedding_size\": {\"values\":[1024,512,256,64]},\n",
    "        \"hidden_size\": {\"values\":[ 1024,512,256,64]},\n",
    "        \"encoder_layers\": {\"values\":[1]},\n",
    "        \"decoder_layers\": {\"values\":[1]},\n",
    "        \"cell_type\": {\"values\":[\"RNN\"]},\n",
    "        \"bi_directional\":{\"values\":[\"No\"]},\n",
    "        \"dropout\":{\"values\":[0.0,0.2,0.3]},\n",
    "        \"attention\":{\"values\":[\"Yes\"]},\n",
    "        \"teach_ratio\":{\"values\":[0.0,0.2,0.4,0.6]}\n",
    "        \n",
    "        }\n",
    "    }\n",
    "\n",
    "    #------Train function-----------\n",
    "\n",
    "    def train_rnn():\n",
    "\n",
    "      #-----initialize project---------\n",
    "\n",
    "      \n",
    "        wandb.init()\n",
    "        \n",
    "       \n",
    "        # ---- Sweep Name-----\n",
    "\n",
    "        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batch_size)+\"_EPOCH_\"+str(wandb.config.epoch)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n",
    "        wandb.run.name = name\n",
    "        \n",
    "\n",
    "        # parameters to pass to functions\n",
    "        \n",
    "        learn_rate = wandb.config.learn_rate\n",
    "        batch_size = wandb.config.batch_size\n",
    "        hidden_size = wandb.config.hidden_size\n",
    "        embedding_size = wandb.config.embedding_size\n",
    "        num_encoder = wandb.config.encoder_layers\n",
    "        num_decoder = wandb.config.decoder_layers\n",
    "        cell_type = wandb.config.cell_type\n",
    "        bidirectional = (wandb.config.bi_directional==\"Yes\")\n",
    "        dropout = wandb.config.dropout\n",
    "        teach_ratio = wandb.config.teach_ratio\n",
    "        epoch = wandb.config.epoch\n",
    "        beam_width =0\n",
    "        encoder =None\n",
    "        decoder = None\n",
    "\n",
    "\n",
    "        if wandb.config.attention == \"Yes\" :\n",
    "            \n",
    "            encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "        else:\n",
    "            \n",
    "            encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "        \n",
    "        wandb.run.save()\n",
    "        wandb.run.finish()\n",
    "    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3__AAtention\")\n",
    "    \n",
    "\n",
    "    # ------Number of experiments we want to run--------\n",
    "    \n",
    "    wandb.agent(sweep_id,function=train_rnn,count=50)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n",
    "#     wandb.agent(sweep_id,function=train_rnn,count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446679c",
   "metadata": {
    "id": "1nRPy10d_ebq",
    "papermill": {
     "duration": 0.012207,
     "end_time": "2023-05-21T04:33:18.587363",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.575156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7f9d8",
   "metadata": {
    "id": "VkKDIHiUgUwH",
    "papermill": {
     "duration": 0.012182,
     "end_time": "2023-05-21T04:33:18.611891",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.599709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002fe70",
   "metadata": {
    "id": "Igy33O64F1ay",
    "papermill": {
     "duration": 0.012236,
     "end_time": "2023-05-21T04:33:18.636720",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.624484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af123d",
   "metadata": {
    "id": "q7e__rzOqvHl",
    "papermill": {
     "duration": 0.012461,
     "end_time": "2023-05-21T04:33:18.661688",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.649227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a11731",
   "metadata": {
    "id": "PPTB1O7EFSzT",
    "papermill": {
     "duration": 0.012596,
     "end_time": "2023-05-21T04:33:18.687328",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.674732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5830c71f",
   "metadata": {
    "id": "FBaYBKQNA8hA",
    "papermill": {
     "duration": 0.012564,
     "end_time": "2023-05-21T04:33:18.712702",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.700138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Wandb sweep runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4944fe",
   "metadata": {
    "papermill": {
     "duration": 0.012184,
     "end_time": "2023-05-21T04:33:18.737324",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.725140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6d4073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:18.763572Z",
     "iopub.status.busy": "2023-05-21T04:33:18.763226Z",
     "iopub.status.idle": "2023-05-21T04:33:18.767412Z",
     "shell.execute_reply": "2023-05-21T04:33:18.766440Z"
    },
    "id": "60ANGwbUrJ9s",
    "papermill": {
     "duration": 0.019723,
     "end_time": "2023-05-21T04:33:18.769470",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.749747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# wandb.finish()\n",
    "# wandb_runs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb1e82",
   "metadata": {
    "id": "apd_UXYMLUg1",
    "papermill": {
     "duration": 0.012682,
     "end_time": "2023-05-21T04:33:18.795882",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.783200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ad24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T09:20:51.591804Z",
     "iopub.status.busy": "2023-05-14T09:20:51.591408Z"
    },
    "id": "CecJGVVp3-rJ",
    "papermill": {
     "duration": 0.012405,
     "end_time": "2023-05-21T04:33:18.820757",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.808352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20fb29",
   "metadata": {
    "id": "1rlYhDeUBgGK",
    "papermill": {
     "duration": 0.01227,
     "end_time": "2023-05-21T04:33:18.845884",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.833614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc4ec6c",
   "metadata": {
    "id": "oITf1FJKBcw8",
    "papermill": {
     "duration": 0.012246,
     "end_time": "2023-05-21T04:33:18.870940",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.858694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Translate prediction to proper words according to dictionary  and save in DataFrame formate (Input , predicted,Actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427ef122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:18.897840Z",
     "iopub.status.busy": "2023-05-21T04:33:18.897034Z",
     "iopub.status.idle": "2023-05-21T04:33:18.906518Z",
     "shell.execute_reply": "2023-05-21T04:33:18.905692Z"
    },
    "id": "UN8EqMnc4Vkw",
    "papermill": {
     "duration": 0.025133,
     "end_time": "2023-05-21T04:33:18.908475",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.883342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_prediction(InDict , input,OutDict,pred,target):\n",
    "    \n",
    "    '''give input and pred in shape of batch_size*seq_len'''\n",
    "\n",
    "    pred = pred[:, 1:-1] # ignore first and last index of each row\n",
    "    input = input[:, :-1] # ignore  last index of each row\n",
    "    target = target[:, 1:-1] # ignore  last index of each row\n",
    "    predictions = [] \n",
    "    Input = [] \n",
    "    Target = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        \n",
    "        stringP=\"\" # Predicted word\n",
    "        stringIn=\"\" # Input word\n",
    "        stringActu = \"\" # Actual string\n",
    "\n",
    "        for j in range(pred.shape[1]):\n",
    "\n",
    "            # Ignore padding\n",
    "            if(target[i][j].item()!=0):\n",
    "              \n",
    "              stringP = stringP + OutDict[pred[i][j].item()]\n",
    "              stringActu = stringActu+OutDict[target[i][j].item()]\n",
    "                    \n",
    "        for j in range(input.shape[1]):\n",
    "            \n",
    "               if(input[i][j].item()!=0):\n",
    "                    \n",
    "                    stringIn = stringIn + InDict[input[i][j].item()]   \n",
    "\n",
    "        # Append words in respective List\n",
    "        \n",
    "        predictions.append(stringP)\n",
    "        Input.append(stringIn)         \n",
    "        Target.append(stringActu)   \n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\"input\": Input, \"predicted\": predictions,\"Actual\":Target})\n",
    "\n",
    "    return df\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddd1b6",
   "metadata": {
    "id": "2GqlGL9ooq5K",
    "papermill": {
     "duration": 0.012291,
     "end_time": "2023-05-21T04:33:18.933708",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.921417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Attention weight heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff98d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:18.960490Z",
     "iopub.status.busy": "2023-05-21T04:33:18.960196Z",
     "iopub.status.idle": "2023-05-21T04:33:19.076838Z",
     "shell.execute_reply": "2023-05-21T04:33:19.075973Z"
    },
    "id": "6L0wefltB7uV",
    "papermill": {
     "duration": 0.132741,
     "end_time": "2023-05-21T04:33:19.079090",
     "exception": false,
     "start_time": "2023-05-21T04:33:18.946349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "def Attension_heatmap(X,Y,encoder, decoder, device,output_size,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type):\n",
    "    \n",
    "    # Assuming you have a tensor named 'data' with shape [num_samples, ...]\n",
    "    num_samples = X.shape[0]\n",
    "    num_selected_samples = batch_size\n",
    "\n",
    "    # Generate random permutation of indices\n",
    "    random_indices = torch.randperm(num_samples)[:num_selected_samples]\n",
    "\n",
    "    # Select the corresponding samples from the tensor\n",
    "    X = X[random_indices]\n",
    "    Y = Y[random_indices]\n",
    "\n",
    "    # Set encoder decoder in evalution Mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # Initialize predicted , runningloss , correct ( predictions)\n",
    "    attention_weights=None\n",
    "    \n",
    "    # Load data into Loader and initialize loss function\n",
    "   \n",
    "    print(X.shape)\n",
    "    # Calculate loss for whole data and total correct predictions \n",
    "    with torch.no_grad():\n",
    "      \n",
    "        \n",
    "        #  push Batch to device\n",
    "        x = X.to(device)\n",
    "        y = Y.to(device)\n",
    "\n",
    "        x = x.transpose(0,1)\n",
    "        y = y.transpose(0,1)\n",
    "\n",
    "        # Encoder forawrd pass\n",
    "        encoder_output, encoder_hidden = encoder(x)\n",
    "        \n",
    "        #handle bidirectional case\n",
    "        if bidirectional:\n",
    "          hidden_size = encoder_output.size(2) // 2\n",
    "          forward_output = encoder_output[:, :, :hidden_size]\n",
    "          backward_output = encoder_output[:, :, hidden_size:]\n",
    "          encoder_output = torch.add(forward_output, backward_output)/2\n",
    "\n",
    "          # print(hidden_size)\n",
    "          if(cell_type==\"LSTM\"):\n",
    "            hidden,state = encoder_hidden\n",
    "            hidden = hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "            state = state.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            state=torch.add(state[0],state[1])/2\n",
    "            encoder_hidden =(hidden,state)\n",
    "\n",
    "          else:\n",
    "            hidden=encoder_hidden.resize(2,num_encoder,batch_size,hidden_size)\n",
    "            encoder_hidden=torch.add(hidden[0],hidden[1])/2\n",
    "\n",
    "        # Initialize the decoder_hidden tensor and decoder_input\n",
    "        decoder_input =(y)[0]\n",
    "        decoder_hidden = generateDecoderHidden(cell_type,num_encoder,num_decoder,encoder_hidden)\n",
    "        \n",
    "        \n",
    "        pred_output=torch.zeros(y.shape[0],batch_size,output_size).to(device)\n",
    "        for k in range(1,y.shape[0]):\n",
    "\n",
    "          \n",
    "          decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output)\n",
    "          \n",
    "        \n",
    "          print(attention.shape)\n",
    "          if(attention_weights==None):\n",
    "            attention_weights=attention\n",
    "          else :\n",
    "            attention_weights = torch.cat([attention_weights,attention],dim = -1)\n",
    "\n",
    "          # Get the index of the maximum probability in each row\n",
    "          max_probs, indices = torch.max(decoder_output, dim=2)\n",
    "\n",
    "          \n",
    "          # Reshape the indices tensor to (batch_size,) for easier indexing\n",
    "          indices = indices.view(batch_size)\n",
    "          decoder_input=indices.clone()\n",
    "\n",
    "        decoder_output,decoder_hidden,attention= decoder(decoder_input, decoder_hidden,encoder_output) \n",
    "        attention_weights = torch.cat([attention_weights,attention],dim = -1)\n",
    "       \n",
    "        print(attention_weights.shape)\n",
    "        # Get predicted Words\n",
    "        attention_weights = (attention_weights.cpu()).numpy()\n",
    "        attention_weights = attention_weights.transpose(1, 2, 0)\n",
    "\n",
    "        # Normalize the attention weights across the input sequence axis\n",
    "        attention_weights = attention_weights / np.sum(attention_weights, axis=2, keepdims=True)\n",
    "        print(attention_weights.shape)\n",
    "\n",
    "        attention_weights_fixed = np.nan_to_num(attention_weights, nan=0.0000001)\n",
    "\n",
    "        # Create a 3x3 grid of subplots for heatmaps\n",
    "        fig = make_subplots(rows=4, cols=4)\n",
    "\n",
    "        # Add heatmaps to the grid\n",
    "        for i in range(batch_size):\n",
    "            heatmap = attention_weights[i]\n",
    "            \n",
    "            x_label , y_label = [] , []\n",
    "\n",
    "            for k in range(X.shape[1]):\n",
    "              char = data.input_lang.index2char[(X[i][k]).item()]\n",
    "              x_label.append(char)\n",
    "            \n",
    "            for k in range(Y.shape[1]):\n",
    "              char = data.output_lang.index2char[(Y[i][k]).item()]\n",
    "              y_label.append(char)\n",
    "            # Create a heatmap trace\n",
    "            heatmap_trace = go.Heatmap(z=heatmap,\n",
    "                                      x=y_label,\n",
    "                                      y=x_label,\n",
    "                                      colorscale='hot',\n",
    "                                      reversescale=True,\n",
    "                                      showscale=False)\n",
    "\n",
    "            # Add the heatmap trace to the subplot\n",
    "            row = (i // 4) + 1\n",
    "            col = (i % 4) + 1\n",
    "            fig.add_trace(heatmap_trace, row=row, col=col)\n",
    "\n",
    "           # Set subplot titles\n",
    "            # Set subplot titles\n",
    "    \n",
    "            fig.update_xaxes(title_text=\"Output Sequence\", row=row, col=col)\n",
    "            fig.update_yaxes(title_text=\"Input Sequnece\", row=row, col=col)\n",
    "\n",
    "            # Update subplot titles\n",
    "            fig.update_layout(title=f\"Attention Heatmap Grid\", height=800, width=800)\n",
    "\n",
    "        # Show the grid of heatmaps\n",
    "        wandb.log({\"heatmap \":fig})\n",
    "\n",
    "        # # Create a 3x3 grid of subplots for heatmaps\n",
    "        # fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "        # # Plot the attention heatmaps in the grid\n",
    "        # for i, ax in enumerate(axes.flatten()):\n",
    "        #     heatmap = attention_weights[i]\n",
    "        #     ax.imshow(heatmap, cmap='hot', interpolation='nearest')\n",
    "        #     x_label , y_label = [] , []\n",
    "\n",
    "        #     for k in range(X.shape[1]):\n",
    "        #       char = data.input_lang.index2char[(X[i][k]).item()]\n",
    "        #       x_label.append(char)\n",
    "            \n",
    "        #     for k in range(Y.shape[1]):\n",
    "        #       char = data.output_lang.index2char[(Y[i][k]).item()]\n",
    "        #       y_label.append(char)\n",
    "        #     ax.set_xticks(np.arange(Y.shape[1]))\n",
    "        #     ax.set_yticks(np.arange(X.shape[1]))\n",
    "        #     ax.set_xticklabels(y_label)\n",
    "        #     ax.set_yticklabels(x_label)\n",
    "\n",
    "        #     ax.set_title(f'Sample {random_indices[i]}')\n",
    "        #     ax.set_xlabel('Decoder Sequence ')\n",
    "        #     ax.set_ylabel('Encoder Sequence ')\n",
    "\n",
    "        # # Adjust spacing\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        # # Log the figure to wandb\n",
    "        # wandb.log({\"attention_heatmaps\": wandb.Image(fig)})\n",
    "\n",
    "        # # Display the figure\n",
    "        # plt.show()\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b96310",
   "metadata": {
    "id": "F8-5RnN2Cpmp",
    "papermill": {
     "duration": 0.012625,
     "end_time": "2023-05-21T04:33:19.104701",
     "exception": false,
     "start_time": "2023-05-21T04:33:19.092076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## For Best run calculate test accuracy and get word to word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cb566",
   "metadata": {
    "id": "JC3PmGiYC0QQ",
    "papermill": {
     "duration": 0.012378,
     "end_time": "2023-05-21T04:33:19.129697",
     "exception": false,
     "start_time": "2023-05-21T04:33:19.117319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ec6fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T04:33:19.156884Z",
     "iopub.status.busy": "2023-05-21T04:33:19.156579Z",
     "iopub.status.idle": "2023-05-21T05:06:00.021189Z",
     "shell.execute_reply": "2023-05-21T05:06:00.020312Z"
    },
    "id": "WFFGOYan5uR6",
    "outputId": "d91f35e6-f247-4500-b1a5-eb48521e64d6",
    "papermill": {
     "duration": 1960.881034,
     "end_time": "2023-05-21T05:06:00.023272",
     "exception": false,
     "start_time": "2023-05-21T04:33:19.142238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: vzbowu45\n",
      "Sweep URL: https://wandb.ai/vilgax/CS6910_Assignment3_best_run/sweeps/vzbowu45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y9s52nsz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: Yes\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbi_directional: No\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteach_ratio: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivam-kharat-94\u001b[0m (\u001b[33mvilgax\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20230521_043322-y9s52nsz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run/runs/y9s52nsz' target=\"_blank\">jolly-sweep-1</a></strong> to <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run/sweeps/vzbowu45' target=\"_blank\">https://wandb.ai/vilgax/CS6910_Assignment3_best_run/sweeps/vzbowu45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run' target=\"_blank\">https://wandb.ai/vilgax/CS6910_Assignment3_best_run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run/sweeps/vzbowu45' target=\"_blank\">https://wandb.ai/vilgax/CS6910_Assignment3_best_run/sweeps/vzbowu45</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run/runs/y9s52nsz' target=\"_blank\">https://wandb.ai/vilgax/CS6910_Assignment3_best_run/runs/y9s52nsz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 27])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 1])\n",
      "torch.Size([27, 16, 22])\n",
      "(16, 22, 27)\n",
      "confusion matrix start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix done\n",
      "['#', '$', '^', 'श', 'स', '्', 'त', 'र', 'ा', 'ग', 'ब', 'ि', 'न', 'द', 'य', 'क', 'ण', 'ं', 'ज', 'ञ', 'ो', 'प', 'व', 'ी', 'ट', 'च', 'े', 'भ', 'म', 'ध', 'ु', 'घ', 'ड', '़', 'ह', 'ल', 'ै', 'इ', 'ॉ', 'ू', 'अ', 'ए', 'ौ', 'आ', 'ई', 'झ', 'ः', 'ख', 'ष', 'उ', 'थ', 'छ', 'ठ', 'ँ', 'ओ', 'फ', 'ढ', 'ऊ', 'ृ', 'ऐ', 'ळ', 'ऋ', 'औ', 'ऑ', 'ॅ', 'ङ', 'ऽ']\n",
      "fig done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Train_acc</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇██████████</td></tr><tr><td>Train_loss</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Acc</td><td>▁▃▄▅▆▆▇▇▇▇▇███████████████████</td></tr><tr><td>Val_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>30</td></tr><tr><td>Train_acc</td><td>89.74609</td></tr><tr><td>Train_loss</td><td>0.03862</td></tr><tr><td>Val_Acc</td><td>35.69336</td></tr><tr><td>Val_loss</td><td>0.51038</td></tr><tr><td>test_acc</td><td>32.78809</td></tr><tr><td>test_loss</td><td>0.57891</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jolly-sweep-1</strong> at: <a href='https://wandb.ai/vilgax/CS6910_Assignment3_best_run/runs/y9s52nsz' target=\"_blank\">https://wandb.ai/vilgax/CS6910_Assignment3_best_run/runs/y9s52nsz</a><br/>Synced 6 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230521_043322-y9s52nsz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Best_Run(data):\n",
    "    \n",
    "    config = {\n",
    "        \"project\":\"CS6910_Assignment3\",\n",
    "        \"method\": 'bayes',\n",
    "        \"metric\": {\n",
    "        'name': 'Val_acc',\n",
    "        'goal': 'maximize'\n",
    "        },\n",
    "        'parameters' :{\n",
    "        \"epoch\": {\"values\":[30]},\n",
    "        \"learn_rate\": {\"values\":[0.001]},\n",
    "        \"batch_size\": {\"values\": [256]},\n",
    "        \"embedding_size\": {\"values\":[ 64]},\n",
    "        \"hidden_size\": {\"values\":[1024]},\n",
    "        \"encoder_layers\": {\"values\":[1]},\n",
    "        \"decoder_layers\": {\"values\":[1]},\n",
    "        \"cell_type\": {\"values\":[\"LSTM\"]},\n",
    "        \"bi_directional\":{\"values\":[\"No\"]},\n",
    "        \"dropout\":{\"values\":[0.3]},\n",
    "        \"attention\":{\"values\":[\"Yes\"]},\n",
    "        \"teach_ratio\":{\"values\":[0.0]}\n",
    "        \n",
    "        }\n",
    "    }\n",
    "    def train_rnn():\n",
    "        wandb.init()\n",
    "        \n",
    "       \n",
    "\n",
    "        name='_CT_'+str(wandb.config.cell_type)+\"_BS_\"+str(wandb.config.batch_size)+\"_EPOCH_\"+str(wandb.config.epoch)+\"_ES_\"+str(wandb.config.embedding_size)+\"_HS_\"+str(wandb.config.hidden_size)\n",
    "        wandb.run.name = name\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        learn_rate = wandb.config.learn_rate\n",
    "        batch_size = wandb.config.batch_size\n",
    "        hidden_size = wandb.config.hidden_size\n",
    "        embedding_size = wandb.config.embedding_size\n",
    "        num_encoder = wandb.config.encoder_layers\n",
    "        num_decoder = wandb.config.decoder_layers\n",
    "        cell_type = wandb.config.cell_type\n",
    "        bidirectional = (wandb.config.bi_directional==\"Yes\")\n",
    "        dropout = wandb.config.dropout\n",
    "        teach_ratio = wandb.config.teach_ratio\n",
    "        epoch = wandb.config.epoch\n",
    "        beam_width =0\n",
    "        encoder =None\n",
    "        decoder = None\n",
    "        test_loss = None\n",
    "        test_acc = None\n",
    "        preds = None\n",
    "\n",
    "        if wandb.config.attention == \"Yes\" :\n",
    "            \n",
    "            encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "            test_loss,test_acc,preds = evaluateAttension(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "            wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc})\n",
    "            Attension_heatmap(data.test_xE,data.test_yE,encoder,decoder,device,data.output_lang.n_chars,16,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "            dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n",
    "            dataframe.to_csv(\"predictions_Attention.csv\")\n",
    "        else:\n",
    "            \n",
    "            encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "            test_loss,test_acc,preds = evaluate(data.test_xE,data.test_yE,encoder, decoder, device,data.output_lang.n_chars,batch_size,bidirectional,hidden_size,num_encoder,num_decoder,cell_type)\n",
    "            wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc*100})\n",
    "            dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n",
    "            dataframe.to_csv(\"predictions_Vannila.csv\")\n",
    "        \n",
    "            \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        print(\"confusion matrix start\")\n",
    "        CM = confusion_matrix(preds,data.test_yE,data.output_lang.n_chars)\n",
    "\n",
    "        print(\"confusion matrix done\")\n",
    "        fig = plot_confusion_matrix(CM,data.output_lang.index2char)\n",
    "        print(\"fig done\")\n",
    "        wandb.log({'confusion_matrix': (fig)})\n",
    "\n",
    "        wandb.run.save()\n",
    "        wandb.run.finish()\n",
    "    sweep_id=wandb.sweep(config,project=\"CS6910_Assignment3_Best_run\")\n",
    "    \n",
    "    \n",
    "    wandb.agent(sweep_id,function=train_rnn,count=1)\n",
    "wandb.finish()  \n",
    "Best_Run(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24700d",
   "metadata": {
    "id": "WXri8nq3acPa",
    "papermill": {
     "duration": 0.01547,
     "end_time": "2023-05-21T05:06:00.054729",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.039259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a0515",
   "metadata": {
    "id": "FvVi7lmazt52",
    "papermill": {
     "duration": 0.015314,
     "end_time": "2023-05-21T05:06:00.086343",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.071029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67c54c",
   "metadata": {
    "id": "XI-xax7_gPf2",
    "papermill": {
     "duration": 0.015443,
     "end_time": "2023-05-21T05:06:00.117650",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.102207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39978e9b",
   "metadata": {
    "id": "yfSl3VLTC8Up",
    "papermill": {
     "duration": 0.015565,
     "end_time": "2023-05-21T05:06:00.148766",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.133201",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec588ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:06:00.181283Z",
     "iopub.status.busy": "2023-05-21T05:06:00.180857Z",
     "iopub.status.idle": "2023-05-21T05:06:00.185337Z",
     "shell.execute_reply": "2023-05-21T05:06:00.184432Z"
    },
    "id": "9cR7pPVjML2S",
    "papermill": {
     "duration": 0.023207,
     "end_time": "2023-05-21T05:06:00.187488",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.164281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# learn_rate = 0.001\n",
    "# batch_size = 32\n",
    "# hidden_size = 256\n",
    "# embedding_size = 256\n",
    "# num_encoder = 2\n",
    "# num_decoder = 2\n",
    "# cell_type = 'LSTM'\n",
    "# bidirectional =True\n",
    "# dropout = 0.2\n",
    "# teach_ratio = 0.5\n",
    "# epoch = 30\n",
    "# beam_width =0\n",
    "# encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "405749c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:06:00.220599Z",
     "iopub.status.busy": "2023-05-21T05:06:00.220317Z",
     "iopub.status.idle": "2023-05-21T05:06:00.226012Z",
     "shell.execute_reply": "2023-05-21T05:06:00.225054Z"
    },
    "id": "hRtX90Xy2gzH",
    "papermill": {
     "duration": 0.024028,
     "end_time": "2023-05-21T05:06:00.227952",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.203924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention= \"No\"\n",
    "learn_rate = 0.001\n",
    "batch_size = 128\n",
    "hidden_size = 512\n",
    "embedding_size = 512\n",
    "num_encoder = 3\n",
    "num_decoder = 4\n",
    "cell_type = 'GRU'\n",
    "bidirectional =True\n",
    "dropout = 0.5\n",
    "teach_ratio = 0.5\n",
    "epoch = 20\n",
    "beam_width =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94f9c90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:06:00.260171Z",
     "iopub.status.busy": "2023-05-21T05:06:00.259926Z",
     "iopub.status.idle": "2023-05-21T05:06:00.264131Z",
     "shell.execute_reply": "2023-05-21T05:06:00.263021Z"
    },
    "id": "F-gb1qoV3_vu",
    "papermill": {
     "duration": 0.022661,
     "end_time": "2023-05-21T05:06:00.266168",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.243507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder = None\n",
    "# decoder = None\n",
    "# wandb.init()\n",
    "# if attention == \"Yes\" :\n",
    "            \n",
    "#     encoder,decoder=trainAttension(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n",
    "# else:\n",
    "\n",
    "#     encoder,decoder=trainSeq2Seq(data,cell_type,embedding_size,num_encoder,num_decoder,hidden_size,batch_size,bidirectional,dropout,beam_width,epoch,learn_rate,teach_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472d17f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:06:00.298962Z",
     "iopub.status.busy": "2023-05-21T05:06:00.298256Z",
     "iopub.status.idle": "2023-05-21T05:06:00.302363Z",
     "shell.execute_reply": "2023-05-21T05:06:00.301598Z"
    },
    "id": "_5mF33wVQKuh",
    "papermill": {
     "duration": 0.022374,
     "end_time": "2023-05-21T05:06:00.304175",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.281801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "        \n",
    "# wandb.log({\"test_loss\":test_loss,\"test_acc\":test_acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea6e4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:06:00.336905Z",
     "iopub.status.busy": "2023-05-21T05:06:00.336192Z",
     "iopub.status.idle": "2023-05-21T05:06:00.340200Z",
     "shell.execute_reply": "2023-05-21T05:06:00.339435Z"
    },
    "id": "FqjBMkbFR2PL",
    "papermill": {
     "duration": 0.022138,
     "end_time": "2023-05-21T05:06:00.342039",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.319901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = preds.to(device)\n",
    "\n",
    "# dataframe = translate_prediction(data.input_lang.index2char,data.test_xE,data.output_lang.index2char,preds,data.test_yE)\n",
    "# dataframe.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1008d",
   "metadata": {
    "id": "aOJE5dYriKu6",
    "papermill": {
     "duration": 0.015401,
     "end_time": "2023-05-21T05:06:00.373457",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.358056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca39fda",
   "metadata": {
    "id": "TQapNbu06s8b",
    "papermill": {
     "duration": 0.015537,
     "end_time": "2023-05-21T05:06:00.404657",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.389120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29eb177",
   "metadata": {
    "id": "Se9DFLwy6Gub",
    "papermill": {
     "duration": 0.015721,
     "end_time": "2023-05-21T05:06:00.436029",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.420308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ad0b",
   "metadata": {
    "id": "aoctb39aiaWn",
    "papermill": {
     "duration": 0.015447,
     "end_time": "2023-05-21T05:06:00.467093",
     "exception": false,
     "start_time": "2023-05-21T05:06:00.451646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1999.504231,
   "end_time": "2023-05-21T05:06:03.305783",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-21T04:32:43.801552",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09301a022d174a38ac11b4a34c675326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0f297834fe9446e4918b521e4fd4f335",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ef5d9a0bd92442dab28112e4baecdb6b",
       "value": 0.0
      }
     },
     "0f297834fe9446e4918b521e4fd4f335": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a430c9ab33f4289a10d5eaf87a8f542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f888def212d94404a439c8f48a428d5a",
        "IPY_MODEL_98edc337f96c4b1f9dd9832ec8627946"
       ],
       "layout": "IPY_MODEL_511aff88bd80458894076c480e65475d"
      }
     },
     "3a908235b9d9481d94c1d1eeb8c9631b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "511aff88bd80458894076c480e65475d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "596ef317ffc54f5f9d2938338c7cda79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c391a2dc26545b8877885cf3468648e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a18c6081663f4f579241ace12877a541",
       "placeholder": "​",
       "style": "IPY_MODEL_782beff13024482e8f1f5d2531e809d4",
       "value": ""
      }
     },
     "71912562a57248a681f285dc2b9eac38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "VBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "VBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6c391a2dc26545b8877885cf3468648e",
        "IPY_MODEL_09301a022d174a38ac11b4a34c675326"
       ],
       "layout": "IPY_MODEL_82046d75cb3542ac96b7dd339d0b74fc"
      }
     },
     "782beff13024482e8f1f5d2531e809d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "82046d75cb3542ac96b7dd339d0b74fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "98edc337f96c4b1f9dd9832ec8627946": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_596ef317ffc54f5f9d2938338c7cda79",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9dae38ba1bb341d890a2a8ec25a1ec22",
       "value": 0.0
      }
     },
     "9dae38ba1bb341d890a2a8ec25a1ec22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a18c6081663f4f579241ace12877a541": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b32207d417464024ab5b3aaa2deadb0c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ef5d9a0bd92442dab28112e4baecdb6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f888def212d94404a439c8f48a428d5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "LabelModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "LabelView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3a908235b9d9481d94c1d1eeb8c9631b",
       "placeholder": "​",
       "style": "IPY_MODEL_b32207d417464024ab5b3aaa2deadb0c",
       "value": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
