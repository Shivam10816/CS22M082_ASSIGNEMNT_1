{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam10816/CS22M082_ASSIGNEMNT_1/blob/q2/neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "hhgoo0AzGUZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33e40d47-31af-4c44-c425-68cfe3b40cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (0.13.10)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.8/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.16.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login"
      ],
      "metadata": {
        "id": "CG7IszZv9655"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "2p4rX01kwJw7"
      },
      "outputs": [],
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "train_data = np.reshape(train_data,(len(train_data),train_data.shape[1]**2))\n",
        "test_data = np.reshape(test_data,(len(test_data),test_data.shape[1]**2))\n",
        "test_labels =np.reshape(test_labels,(1,len(test_data)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOS7o3xrG1Yn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()\n",
        "train_data = np.reshape(train_data/255.0,(len(train_data),train_data.shape[1]**2))\n",
        "test_data = np.reshape(test_data/255.0,(len(test_data),test_data.shape[1]**2))\n",
        "test_labels =np.reshape(test_labels,(1,len(test_data)))\n",
        "print(np.max(train_data))\n",
        "class neural_network:\n",
        "\n",
        "  #it initializes W and b\n",
        "  def __init__(self,train_data,train_label,hi):\n",
        "    \n",
        "    self.train_data=train_data\n",
        "    self.train_label=train_label\n",
        "    self.rndm()\n",
        "  \n",
        "  def xav(self):\n",
        "    l= train_data.shape[1]\n",
        "\n",
        "    self.W =[self.xavier_init(hi[0],l)] \n",
        "    self.b =[self.xavier_init(1,hi[0])]\n",
        "    for i in range(1,len(hi)) :\n",
        "      self.W.append(self.xavier_init(hi[i],hi[i-1]))\n",
        "      self.b.append(self.xavier_init(1,hi[i])) \n",
        "    self.W.append(self.xavier_init(10,hi[-1]))\n",
        "    \n",
        "    self.b.append(self.xavier_init(1,10))\n",
        "  \n",
        "\n",
        "  def rndm(self):\n",
        "    l= train_data.shape[1]\n",
        "\n",
        "    self.W =[np.random.randn(hi[0],l)] \n",
        "    self.b =[np.zeros((1,hi[0]))]\n",
        "    for i in range(1,len(hi)) :\n",
        "      self.W.append(np.random.randn(hi[i],hi[i-1]))\n",
        "      self.b.append(np.zeros((1,hi[i]))) \n",
        "    self.W.append(np.random.randn(10,hi[-1]))\n",
        "    \n",
        "    self.b.append(np.random.randn(1,10))\n",
        "  \n",
        "  def WX_plus_B(self,W, X, b):\n",
        "    \n",
        "    result = np.dot(X, W.transpose())\n",
        "    row_count = result.shape[0]\n",
        "    \n",
        "    row_matrix_repeated = np.tile(b, (row_count, 1))\n",
        "    return result + row_matrix_repeated\n",
        "\n",
        "    \n",
        "  def xavier_init(self,input_size, output_size):\n",
        "    \"\"\"\n",
        "    Initialize weights using Xavier initialization.\n",
        "\n",
        "    Parameters:\n",
        "    input_size (int): number of input units.\n",
        "    output_size (int): number of output units.\n",
        "\n",
        "    Returns:\n",
        "    weights (ndarray): array of shape (input_size, output_size) containing the initialized weights.\n",
        "    \"\"\"\n",
        "    # Calculate the variance of the weights\n",
        "    variance = 2.0 / (input_size + output_size)\n",
        "\n",
        "    # Calculate the standard deviation of the weights\n",
        "    standard_deviation = np.sqrt(variance)\n",
        "\n",
        "    # Generate random weights from a normal distribution with mean 0 and standard deviation standard_deviation\n",
        "    weights = np.random.normal(loc=0, scale=standard_deviation, size=(input_size, output_size))\n",
        "\n",
        "    return weights\n",
        "\n",
        "  #calculates sigmoid for matrix\n",
        "  def sigmoid(self,x):\n",
        "  \n",
        "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "  \n",
        "  def sum_columns(self,matrix):\n",
        "    if isinstance(matrix, np.ndarray):\n",
        "        # if matrix is a numpy array, convert it to a list\n",
        "        matrix = matrix.tolist()\n",
        "    \n",
        "    # sum the elements of each column and store in a list\n",
        "    column_sums = [sum(col) for col in zip(*matrix)]\n",
        "    \n",
        "    # convert the list to a 2D matrix of shape (1 x n)\n",
        "    row_matrix = np.array([column_sums])\n",
        "    \n",
        "    return row_matrix\n",
        "  #softmax for matrix\n",
        "  def softmax(self,x):\n",
        "    # Subtract the maximum value in each row from all the values in that row\n",
        "    # to prevent numerical instability from very large or very small values\n",
        "    # in the exponentials of the softmax function.\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
        "  \n",
        "  def subtract_matrices(self,W, W_theta, step_size):\n",
        "    \"\"\"\n",
        "    Subtract the matrices in the second list from the matrices in the first list, after multiplying the matrices in the\n",
        "    second list by a step size.\n",
        "\n",
        "    Args:\n",
        "        first_list (list): A list of numpy arrays representing the first set of matrices.\n",
        "        second_list (list): A list of numpy arrays representing the second set of matrices.\n",
        "        step_size (float): The step size to multiply the second set of matrices by.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of numpy arrays representing the result of subtracting the second set of matrices from the first set\n",
        "        of matrices after multiplying the second set of matrices by the step size.\n",
        "    \"\"\"\n",
        "    result_list = []\n",
        "    for i in range(len(self.W)):\n",
        "        result = W[i] - step_size * (W_theta[i]/self.batch_size)\n",
        "        result_list.append(result)\n",
        "    return result_list\n",
        "\n",
        "  def sigmoid_derivative(self,matrix):\n",
        "    \"\"\"\n",
        "    Calculate the derivative of the sigmoid function on a 2D matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (numpy.ndarray): A numpy array representing the matrix.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A numpy array representing the result of calculating the sigmoid derivative on the matrix.\n",
        "    \"\"\"\n",
        "    shift = np.max(matrix, axis=1, keepdims=True)\n",
        "    exp_matrix = np.exp(matrix - shift)\n",
        "    sig = 1 / (1 + exp_matrix)\n",
        "    return sig * (1 - sig)\n",
        "\n",
        "  def forward_pro(self,X):\n",
        "    A=[]\n",
        "    H=[]\n",
        "    A.append(self.WX_plus_B(self.W[0],X,self.b[0])) # a0 = WoX +bo\n",
        "\n",
        "    for i in range(1,len(hi)):\n",
        "\n",
        "      H.append(self.sigmoid(A[-1])) # hi = g(ai)\n",
        "      #print(H[i-1])\n",
        "      A.append( self.WX_plus_B(self.W[i],H[-1],self.b[i])) # ai = WiX +bi\n",
        "\n",
        "    H.append(self.sigmoid(A[-1]))\n",
        "    A.append(self.WX_plus_B(self.W[-1],H[-1],self.b[-1]))\n",
        "    \n",
        "    y_hat = self.softmax((A[-1]))\n",
        "    \n",
        "    \n",
        "    \n",
        "    return A,H,y_hat\n",
        "\n",
        "  def back_prop(self,X,Y,A,H,y_hat):\n",
        "    W_theta , b_theta,H_theta,A_theta =[],[],[],[]\n",
        "    #print(np.argmax(y_hat),lable)\n",
        "    ey = np.zeros((y_hat.shape[0],y_hat.shape[1]))\n",
        "\n",
        "    for i in range(0,len(Y)):\n",
        "      ey[i][Y[i]]=1\n",
        "  \n",
        "    L =len(A)\n",
        "    A_theta.append((-(ey-y_hat)))\n",
        "    \n",
        "    #-------------------------\n",
        "    for k in range(L-1,0,-1):\n",
        "      \n",
        "      W_theta.append((np.matmul(A_theta[-1].transpose(),H[k-1])+self.reg*self.W[k]) ) # athetak*h[k-1]\n",
        "      b_theta.append( self.sum_columns(A_theta[-1]))\n",
        "      H_theta.append(np.matmul(A_theta[-1],self.W[k]))\n",
        "  \n",
        "      A_theta.append(H_theta[-1]*self.sigmoid_derivative(A[k-1]))\n",
        "\n",
        "    W_theta.append((np.matmul(A_theta[-1].transpose(),X)+self.reg*self.W[0]))\n",
        "    b_theta.append(self.sum_columns(A_theta[-1]))\n",
        "\n",
        "    W_theta.reverse()\n",
        "    b_theta.reverse()\n",
        "\n",
        "    self.cross_entropy(y_hat,Y)\n",
        "    # print(\"-------W_theta-----\")\n",
        "    # for i in W_theta :\n",
        "    #   print(i.shape)\n",
        "    # print(\"-------b_theta-----\")\n",
        "    # for i in b_theta :\n",
        "    #print(i.shape)\n",
        "    # print(\"-------A-----\")\n",
        "    # for i in A_theta :\n",
        "    #   print(i.shape)\n",
        "    # print(\"-------H-----\")\n",
        "    # for i in H_theta :\n",
        "    #   print(i.shape)\n",
        "    \n",
        "    return W_theta , b_theta\n",
        "\n",
        "  def accuracy(self, X_test, y_test):\n",
        "    \n",
        "    # Feed forward through the network\n",
        "    A,H,y_hat =self.forward_pro(X_test)\n",
        "    \n",
        "    \n",
        "    y_pred = np.argmax(y_hat, axis=1)\n",
        "    print(y_pred.shape)\n",
        "    # Calculate accuracy\n",
        "    acc = np.mean(y_pred == y_test)\n",
        "    # Calculate accuracy\n",
        "    \n",
        "\n",
        "    return acc\n",
        "  def cross_entropy(self,y_hat,Y):\n",
        "      sum=0.0;\n",
        "      for i in range(0,len(Y)):\n",
        "        sum+=(-np.log2(y_hat[i][Y[i]]))\n",
        "      sum/= float(len(Y))\n",
        "      print(sum)\n",
        "  \n",
        "  def sgd(self,step_size,batch_size,epoch,reg):\n",
        "    N = int(len(self.train_data)/batch_size)\n",
        "    self.batch_size = batch_size\n",
        "    self.reg =reg\n",
        "    for e in range(0,epoch):\n",
        "      start_time = time.time()\n",
        "      for k in range(0,N):\n",
        "          minibatch = self.train_data[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          minibatch_lable=self.train_label[k*batch_size:min(k*batch_size+batch_size,len(self.train_data))]\n",
        "          \n",
        "          A,H,y_hat=self.forward_pro(minibatch)\n",
        "\n",
        "          dW,db = self.back_prop(minibatch,minibatch_lable,A,H,y_hat)\n",
        "          # print(np.min(dW[0]),np.min(dW[1]),np.min(dW[2]))\n",
        "          # print(np.min(db[0]),np.min(db[1]),np.min(db[2]))\n",
        "          # print(np.max(dW[0]),np.max(dW[1]),np.max(dW[2]))\n",
        "          # print(np.max(db[0]),np.max(db[1]),np.max(db[2]))\n",
        "          # print(\"\\n\\n\\n\")\n",
        "          self.b =self.subtract_matrices(self.b,db,step_size)\n",
        "          self.W =self.subtract_matrices(self.W,dW,step_size)\n",
        "          # print(np.min(Net.W[0]),np.min(Net.W[1]),np.min(Net.W[2]))\n",
        "          # print(np.max(Net.W[0]),np.max(Net.W[1]),np.max(Net.W[2]))\n",
        "          # print(np.min(Net.b[0]),np.min(Net.b[1]),np.min(Net.b[2]))\n",
        "\n",
        "          # print(np.max(Net.b[0]),np.max(Net.b[1]),np.max(Net.b[2]))\n",
        "          # print(\"\\n\\n\\n\")\n",
        "          \n",
        "      print(\"epoch \",e ,\"  %s seconds \" % (time.time() - start_time))\n",
        "     \n",
        "      \n",
        "hi=[32,32,32]   \n",
        "Net = neural_network(train_data,train_labels,hi)\n",
        "\n",
        "#print(\"accuracy :-\",Net.accuracy(test_data,test_labels)*100,\"%\")\n",
        "Net.sgd(0.01,16,10,0)\n",
        "#print(\"accuracy :-\",Net.accuracy(test_data,test_labels)*100,\"%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81ZgkBC9_bGE",
        "outputId": "4414ac3b-ce58-40a5-ef5f-6630113305c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.59"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "Net.accuracy(test_data,test_labels)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pUXXVOUXt91X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "1f538fd0-5ab4-492c-8f64-bfc1c023f905"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-f699ff0d0afb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Net.sgd(0.0001,16,100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Net.calculate_accuracy(test_data,test_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mones\u001b[0;34m(shape, dtype, order, like)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ones_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unsafe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '50' as a data type"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5ldCCJ-Jxy6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aysDESkXrvaz"
      },
      "outputs": [],
      "source": [
        "print(test_data.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2nJHtRzKJeg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMf0z38gsl/nxhxOimad/RG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}